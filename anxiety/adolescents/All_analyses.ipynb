{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.io import loadmat\n",
    "import pingouin as pg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-detection",
   "metadata": {},
   "source": [
    "## __Option A:__ Preprocessing of the data:\n",
    "\n",
    "#### Including aggregation of data from both measurements and across all sessions, including global min-max-scaling and classification as responders / discriminators\n",
    "\n",
    "#### Please specify the following variables:\n",
    "`SAVE`: Whether you want to save the preprocessed data (boolean) <br>\n",
    "`session_for_classification`: The name of the session you would like to use for the classification (string) <br>\n",
    "`t1`, `t2`: The timepoints that will be used for making the classifcation (e.g. t1=0 and t2=5) (integer) <br>\n",
    "`STDDEV_FACTOR`: How large (i.e. how many standard-deviations) does the difference between t1 and t2 have to be, to acceppt responder / discriminator classification? (integer or float)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "session_for_classification = 'acq2'\n",
    "t1 = 0\n",
    "t2 = 5\n",
    "STDDEV_FACTOR = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-romantic",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "l_files = ['EDA_single_1Hz_Normalized1s_-1_15_Dennis.xlsx', 'HR_single_1Hz_Normalized1s_-1_15_Dennis.xlsx']\n",
    "l_sessions = ['preacq', 'acq1', 'acq2', 'gen1', 'gen2', 'ext']\n",
    "\n",
    "#l_files = ['HR_single_1Hz_Normalized1s_-1_15_Dennis.xlsx']\n",
    "#l_sessions = ['preacq']\n",
    "\n",
    "l_dfs_per_measurement = []\n",
    "\n",
    "for file in l_files:\n",
    "    if file.startswith('EDA'):\n",
    "        measurement = 'EDA'\n",
    "    elif file.startswith('HR'):\n",
    "        measurement = 'HR'\n",
    "        \n",
    "    df_dict =  pd.read_excel(file, sheet_name = None)\n",
    "    l_sheets = list(df_dict.keys())\n",
    "    \n",
    "    l_dfs_per_session = []\n",
    "    for session in l_sessions:\n",
    "        \n",
    "        # Identify all sheets that contain data of the respective session:\n",
    "        l_session_sheets = []\n",
    "        for sheet in l_sheets: \n",
    "            if session in sheet:\n",
    "                l_session_sheets.append(sheet)\n",
    "        \n",
    "        l_dfs_CSminus_data = []\n",
    "        l_dfs_CSplus_data = []\n",
    "        \n",
    "        for sheet in l_session_sheets:\n",
    "            # subject as idx name makes sense after transposing the DF later on\n",
    "            df_dict[sheet].insert(0, '', list(range(-1, 16)))\n",
    "            df_dict[sheet].set_index('', drop=True, inplace=True)\n",
    "            \n",
    "            if sheet.endswith(('CS-', 'CS- ')):\n",
    "                l_dfs_CSminus_data.append(df_dict[sheet])\n",
    "            \n",
    "            if sheet.endswith(('CS+', 'CS+ ')):\n",
    "                l_dfs_CSplus_data.append(df_dict[sheet])\n",
    "        \n",
    "        # Now concat these data together to obtain a single DF for the entire session:\n",
    "        df_CSminus_per_session = pd.concat(l_dfs_CSminus_data, axis=1)\n",
    "\n",
    "        df_CSminus_per_session = df_CSminus_per_session.transpose()\n",
    "        df_CSminus_per_session = df_CSminus_per_session.reset_index()\n",
    "        df_CSminus_per_session = df_CSminus_per_session.rename(columns={'index': 'subject_id'})\n",
    "        df_CSminus_per_session.insert(1, 'stim_count', 'to_be_filled')\n",
    "        df_CSminus_per_session.insert(1, 'value_type', 'abs_CS-')        \n",
    "        \n",
    "        df_CSplus_per_session = pd.concat(l_dfs_CSplus_data, axis=1)\n",
    "        df_CSplus_per_session = df_CSplus_per_session.transpose()\n",
    "        df_CSplus_per_session = df_CSplus_per_session.reset_index()\n",
    "        df_CSplus_per_session = df_CSplus_per_session.rename(columns={'index': 'subject_id'})\n",
    "        df_CSplus_per_session.insert(1, 'stim_count', 'to_be_filled')\n",
    "        df_CSplus_per_session.insert(1, 'value_type', 'abs_CS+')\n",
    "\n",
    "        \n",
    "        #df_per_session = pd.concat([df_CSminus_per_session, df_CSplus_per_session], axis=0)\n",
    "        for df_temp in [df_CSminus_per_session, df_CSplus_per_session]:\n",
    "            l_counts = [elem[elem.index('_') + 1:] for elem in list(df_temp['subject_id'].values)]\n",
    "            df_temp['stim_count'] = l_counts\n",
    "            l_subject_ids = [elem[: elem.index('E_')] if 'E_' in elem else elem[: elem.index('_')] for elem in list(df_temp['subject_id'].values)]\n",
    "            df_temp['subject_id'] = l_subject_ids\n",
    "            df_temp.insert(1, 'measurement', measurement)\n",
    "            df_temp.insert(1, 'session', session)\n",
    "            df_temp.insert(1, 'group', 'to_be_filled')\n",
    "            l_groups = ['control' if elem.startswith('GES') else 'anxiety' for elem in list(df_temp['subject_id'].values)]\n",
    "            df_temp['group'] = l_groups\n",
    "        \n",
    "        df_per_session = pd.concat([df_CSminus_per_session, df_CSplus_per_session], axis=0)\n",
    "        df_per_session.reset_index(drop=True, inplace=True)\n",
    "        l_dfs_per_session.append(df_per_session)\n",
    "\n",
    "    # Concat the reshaped dataframes from all sessions that contain the \"absolute\" values \n",
    "    # Note: already normalized with Jérémys code to stimulus onset -1.0s\n",
    "    df_abs = pd.concat(l_dfs_per_session, axis=0)\n",
    "    df_abs.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    l_dfs_per_measurement.append(df_abs)\n",
    "\n",
    "df = pd.concat(l_dfs_per_measurement, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "l_df_per_gen_session = []\n",
    "\n",
    "#for gen_session in ['gen1', 'gen2']:\n",
    "for gen_session in ['gen1']:\n",
    "    if gen_session == 'gen1':\n",
    "        l_files = ['Gen1.xlsx', 'Gen2.xlsx', 'Gen3.xlsx', 'Gen4.xlsx']\n",
    "        char = '.'\n",
    "    if gen_session == 'gen2':\n",
    "        l_files = ['Gen1_2.xlsx', 'Gen2_2.xlsx', 'Gen3_2.xlsx', 'Gen4_2.xlsx']\n",
    "        char = '_'\n",
    "    \n",
    "    l_dfs_per_GS = []\n",
    "    \n",
    "    for file in l_files:\n",
    "        stimulus = file[:file.index(char)]\n",
    "        stimulus = stimulus.replace('en', 'S')\n",
    "        \n",
    "        l_dfs_individual_measurements = []\n",
    "        \n",
    "        for measurement in ['HR', 'EDA']:\n",
    "            if measurement == 'HR':\n",
    "                sheet_name = 'Singles'\n",
    "            elif measurement == 'EDA':\n",
    "                sheet_name = 'SinglesSC'\n",
    "            \n",
    "            df_temp = pd.read_excel(file, sheet_name = sheet_name)\n",
    "\n",
    "            df_temp.insert(0, '', list(range(-1, 16)))\n",
    "            df_temp.set_index('', drop=True, inplace=True)\n",
    "\n",
    "            df_temp = df_temp.transpose()\n",
    "            df_temp = df_temp.reset_index()\n",
    "            df_temp = df_temp.rename(columns={'index': 'subject_id'})\n",
    "            df_temp.insert(1, 'stim_count', 'to_be_filled')\n",
    "            df_temp.insert(1, 'value_type', 'abs_' + stimulus)\n",
    "\n",
    "            l_counts = [elem[elem.index('_') + 1:] for elem in list(df_temp['subject_id'].values)]    \n",
    "            df_temp['stim_count'] = l_counts \n",
    "            l_subject_ids = [elem[: elem.index('E_')] if 'E_' in elem else elem[: elem.index('_')] for elem in list(df_temp['subject_id'].values)]\n",
    "            df_temp['subject_id'] = l_subject_ids\n",
    "            # Remember to change to generic!\n",
    "            df_temp.insert(1, 'measurement', measurement)\n",
    "            df_temp.insert(1, 'session', gen_session)\n",
    "            df_temp.insert(1, 'group', 'to_be_filled')\n",
    "            l_groups = ['control' if elem.startswith('GES') else 'anxiety' for elem in list(df_temp['subject_id'].values)]\n",
    "            df_temp['group'] = l_groups\n",
    "            \n",
    "            l_dfs_individual_measurements.append(df_temp)\n",
    "            \n",
    "        df_individual_GS = pd.concat(l_dfs_individual_measurements, axis=0)\n",
    "        df_individual_GS.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        l_dfs_per_GS.append(df_individual_GS)\n",
    "    \n",
    "    df_all_GS_one_session = pd.concat(l_dfs_per_GS, axis=0)\n",
    "    df_all_GS_one_session.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    l_df_per_gen_session.append(df_all_GS_one_session)\n",
    "    \n",
    "df_all_GS_both_sessions = pd.concat(l_df_per_gen_session, axis=0)\n",
    "df_all_GS_both_sessions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = pd.concat([df, df_all_GS_both_sessions], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now global normalization is done\n",
    "l_dfs_global_norm = []\n",
    "\n",
    "for measurement in ['EDA', 'HR']:\n",
    "    \n",
    "    l_value_types = ['abs_CS+', 'abs_CS-', 'abs_GS1', 'abs_GS2', 'abs_GS3', 'abs_GS4']\n",
    "    # Select the data\n",
    "    df_temp = df.loc[(df['measurement'] == measurement) & (df['value_type'].isin(l_value_types))].copy()\n",
    "\n",
    "    # Since the data contains positive and negative values, the absolute value of the min is added to each value\n",
    "    # This forces all values to be positive and regular min-max-scaling can be performed\n",
    "    global_min = df_temp.iloc[:, 6:23].min().min()\n",
    "    df_temp.iloc[:, 6:23] = df_temp.iloc[:, 6:23] + abs(global_min)\n",
    "    new_min = df_temp.iloc[:, 6:23].min().min()\n",
    "    new_max = df_temp.iloc[:, 6:23].max().max()\n",
    "    df_temp.iloc[:, 6:23] = (df_temp.iloc[:, 6:23] - new_min) / (new_max - new_min)\n",
    "    for value_type in l_value_types:\n",
    "        wo_prefix = value_type[value_type.index('_'):]\n",
    "        df_temp.loc[df_temp['value_type'] == value_type, 'value_type'] = 'norm_global' + wo_prefix\n",
    "    l_dfs_global_norm.append(df_temp)\n",
    "    \n",
    "df = pd.concat([df] + l_dfs_global_norm, axis = 0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df.loc[(df['session'] == 'ext') & (df['stim_count'].isin(['1', '2', '3', '4', '5', '6'])), 'session'] = 'ext1'\n",
    "df.loc[(df['session'] == 'ext') & (df['stim_count'].isin(['7', '8', '9', '10', '11', '12'])), 'session'] = 'ext2'\n",
    "df.loc[(df['session'] == 'ext') & (df['stim_count'].isin(['13', '14', '15', '16', '17', '18'])), 'session'] = 'ext3'\n",
    "\n",
    "\n",
    "l_subjects = df['subject_id'].unique()\n",
    "\n",
    "\n",
    "for measurement in ['EDA', 'HR']:\n",
    "    for subject in l_subjects:\n",
    "        for session in ['preacq', 'acq1', 'acq2', 'gen2', 'ext1', 'ext2', 'ext3']:\n",
    "            \n",
    "            df_temp = df.loc[(df['measurement'] == measurement) & (df['session'] == session) \n",
    "                                     & (df['subject_id'] == subject) & (df['value_type'].isin(['norm_global_CS+', 'norm_global_CS-']))].copy()            \n",
    "            \n",
    "            df_meta = df_temp.iloc[:3, 0:6].copy()\n",
    "            df_meta['value_type'] = ['norm_global_CS+', 'norm_global_CS-', 'norm_global_discrim_ratio']\n",
    "            df_meta['stim_count'] = ['session_mean', 'session_mean', 'session_mean']\n",
    "            df_meta.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            series_CSplus = df_temp.loc[df_temp['value_type'] == 'norm_global_CS+'].iloc[:,6:23].mean()\n",
    "            series_CSminus = df_temp.loc[df_temp['value_type'] == 'norm_global_CS-'].iloc[:,6:23].mean()\n",
    "            df_temp_CSplus = series_CSplus.to_frame().T\n",
    "            df_temp_CSminus = series_CSminus.to_frame().T\n",
    "            \n",
    "            df_discrim = pd.concat([df_temp_CSplus, df_temp_CSminus])\n",
    "\n",
    "            df_discrim = df_discrim.append(df_discrim.iloc[0,:] / (df_discrim.iloc[0,:] + df_discrim.iloc[1,:]), ignore_index=True)\n",
    "\n",
    "            df_to_append = pd.concat([df_meta, df_discrim], axis=1)\n",
    "\n",
    "            df = df.append(df_to_append, ignore_index=True)\n",
    "        \n",
    "        #for session in ['gen1', 'gen2']:\n",
    "        for session in ['gen1']:\n",
    "            df_temp = df.loc[(df['measurement'] == measurement) & (df['session'] == session) \n",
    "                         & (df['subject_id'] == subject) & (df['value_type'].isin(['norm_global_CS+', 'norm_global_CS-',\n",
    "                                                                                   'norm_global_GS1', 'norm_global_GS2',\n",
    "                                                                                  'norm_global_GS3', 'norm_global_GS4']))].copy()            \n",
    "            \n",
    "            df_meta = df_temp.iloc[:11, 0:6].copy()\n",
    "            df_meta['value_type'] = ['norm_global_CS+', 'norm_global_CS-',\n",
    "                                     'norm_global_GS1', 'norm_global_GS2', 'norm_global_GS3', 'norm_global_GS4',\n",
    "                                     'norm_global_discrim_ratio',\n",
    "                                     'norm_global_discrim_ratio_GS1', 'norm_global_discrim_ratio_GS2','norm_global_discrim_ratio_GS3','norm_global_discrim_ratio_GS4']\n",
    "            df_meta['stim_count'] = ['session_mean', 'session_mean', \n",
    "                                     'session_mean', 'session_mean', 'session_mean', 'session_mean',\n",
    "                                     'session_mean',\n",
    "                                     'session_mean', 'session_mean', 'session_mean', 'session_mean']\n",
    "            df_meta.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            series_CSplus = df_temp.loc[df_temp['value_type'] == 'norm_global_CS+'].iloc[:,6:23].mean()\n",
    "            series_CSminus = df_temp.loc[df_temp['value_type'] == 'norm_global_CS-'].iloc[:,6:23].mean()     \n",
    "\n",
    "            series_GS1 = df_temp.loc[df_temp['value_type'] == 'norm_global_GS1'].iloc[:,6:23].mean()\n",
    "            series_GS2 = df_temp.loc[df_temp['value_type'] == 'norm_global_GS2'].iloc[:,6:23].mean()\n",
    "            series_GS3 = df_temp.loc[df_temp['value_type'] == 'norm_global_GS3'].iloc[:,6:23].mean()\n",
    "            series_GS4 = df_temp.loc[df_temp['value_type'] == 'norm_global_GS4'].iloc[:,6:23].mean()\n",
    "            \n",
    "            df_temp_CSplus = series_CSplus.to_frame().T\n",
    "            df_temp_CSminus = series_CSminus.to_frame().T    \n",
    "            \n",
    "            df_temp_GS1 = series_GS1.to_frame().T\n",
    "            df_temp_GS2 = series_GS2.to_frame().T\n",
    "            df_temp_GS3 = series_GS3.to_frame().T\n",
    "            df_temp_GS4 = series_GS4.to_frame().T\n",
    "            \n",
    "            df_discrim = pd.concat([df_temp_CSplus, df_temp_CSminus, df_temp_GS1, df_temp_GS2, df_temp_GS3, df_temp_GS4])\n",
    "            \n",
    "            df_discrim = df_discrim.append(df_discrim.iloc[0,:] / (df_discrim.iloc[0,:] + df_discrim.iloc[1,:]), ignore_index=True)\n",
    "            \n",
    "            df_discrim = df_discrim.append(df_discrim.iloc[0,:] / (df_discrim.iloc[0,:] + df_discrim.iloc[2,:]), ignore_index=True)\n",
    "            df_discrim = df_discrim.append(df_discrim.iloc[0,:] / (df_discrim.iloc[0,:] + df_discrim.iloc[3,:]), ignore_index=True)\n",
    "            df_discrim = df_discrim.append(df_discrim.iloc[0,:] / (df_discrim.iloc[0,:] + df_discrim.iloc[4,:]), ignore_index=True)\n",
    "            df_discrim = df_discrim.append(df_discrim.iloc[0,:] / (df_discrim.iloc[0,:] + df_discrim.iloc[5,:]), ignore_index=True)\n",
    "            \n",
    "\n",
    "            #df_discrim.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            df_to_append = pd.concat([df_meta, df_discrim], axis=1)\n",
    "            \n",
    "            df = df.append(df_to_append, ignore_index=True)\n",
    "\n",
    "if SAVE:\n",
    "    df.to_csv('all_normalized_single_data_with_gen1.csv')\n",
    "\n",
    "\n",
    "# Classification of each subject as responder and discriminator (each can be different for the individual measurement, e.g. HR responder & EDA non-responder)\n",
    "\n",
    "# If-condition only added to make multiple subsequent computations possible (column can´t be added if it already exists)\n",
    "if 'EDA_discriminator' not in df.columns:\n",
    "    df.insert(2, 'EDA_discriminator', 'to_be_assigned')\n",
    "    df.insert(2, 'EDA_responder', 'to_be_assigned')\n",
    "    df.insert(2, 'HR_discriminator', 'to_be_assigned')\n",
    "    df.insert(2, 'HR_responder', 'to_be_assigned')\n",
    "\n",
    "# iterate through both measurements individually\n",
    "for MEASUREMENT in ['HR', 'EDA']:\n",
    "    for subject in df['subject_id'].unique():\n",
    "        \n",
    "        # select all data of the respective subject from the session that is to be used for the classification as series, since there are multiple presentations of each stimulus\n",
    "        # CS- at t1\n",
    "        series_CSminus_t1 = df.loc[(df['session'] == session_for_classification) & (df['measurement'] == MEASUREMENT) \n",
    "                                    & (df['value_type'] == 'norm_global_CS-') & (df['stim_count'] != 'session_mean') & (df['subject_id'] == subject), t1]\n",
    "        # CS- at t2\n",
    "        series_CSminus_t2 =  df.loc[(df['session'] == session_for_classification) & (df['measurement'] == MEASUREMENT) \n",
    "                                    & (df['value_type'] == 'norm_global_CS-') & (df['stim_count'] != 'session_mean') & (df['subject_id'] == subject), t2]\n",
    "        # CS+ at t1\n",
    "        series_CSplus_t1 = df.loc[(df['session'] == session_for_classification) & (df['measurement'] == MEASUREMENT) \n",
    "                                    & (df['value_type'] == 'norm_global_CS+') & (df['stim_count'] != 'session_mean') & (df['subject_id'] == subject), t1]\n",
    "        # CS+ at t2\n",
    "        series_CSplus_t2 =  df.loc[(df['session'] == session_for_classification) & (df['measurement'] == MEASUREMENT) \n",
    "                                    & (df['value_type'] == 'norm_global_CS+') & (df['stim_count'] != 'session_mean') & (df['subject_id'] == subject), t2]        \n",
    "        \n",
    "        # Now compute a series that contains the differences for each pair of presentations:\n",
    "        series_diff_CSminus = series_CSminus_t2 - series_CSminus_t1\n",
    "        series_diff_CSplus = series_CSplus_t2 - series_CSplus_t1  \n",
    "\n",
    "        # Since the definitions of responder and discriminator are different for the individual measurements, this section is split\n",
    "        if MEASUREMENT == 'HR':\n",
    "            # First, let´s check whether the individual fullfills the criteria of being a HR responder, i.e.:\n",
    "            # The difference in the HR between t2 and t1 is negative (= a decrease in HR)\n",
    "            # The difference between t2 and t1 in the mean HR responses after the CS+ is larger than STDDEV_FACTOR * the standard deviation of the responses at t1 \n",
    "            if (series_diff_CSplus.mean() < 0) & (abs(series_diff_CSplus.mean()) > STDDEV_FACTOR*series_CSplus_t1.std()):\n",
    "                responder = True\n",
    "            else:\n",
    "                responder = False\n",
    "            # Now let´s check whether the individual fullfills the criteria of being a HR discriminator, i.e.:\n",
    "            # The subject is already classified as being a responder\n",
    "            # The difference in the HR differences (between t1 and t2) after presentation of the CS+ or CS-, is larger than STDDEV_FACTOR* the standard deviation of the CS- differences\n",
    "            if (responder == True) & (series_diff_CSplus.mean() < (series_diff_CSminus.mean() - STDDEV_FACTOR*series_diff_CSminus.std())):\n",
    "                discriminator = True\n",
    "            else:\n",
    "                discriminator = False\n",
    "            \n",
    "            \n",
    "        elif MEASUREMENT == 'EDA':\n",
    "            # Similar as for HR, but now we check for an increase in EDA between t1 and t2:\n",
    "            if (series_diff_CSplus.mean() > 0) & (abs(series_diff_CSplus.mean()) > STDDEV_FACTOR*series_CSplus_t1.std()):\n",
    "                responder = True\n",
    "            else:\n",
    "                responder = False\n",
    "            # Similar as for HR, but now we check for a larger increase in EDA between t1 and t2 after CS+ presentations, compared to after CS- presentations\n",
    "            if (responder == True) & (series_diff_CSplus.mean() > (series_diff_CSminus.mean() + STDDEV_FACTOR*series_diff_CSminus.std())):\n",
    "                discriminator = True\n",
    "            else:\n",
    "                discriminator = False\n",
    "        \n",
    "        # The results are stored in the DataFrame\n",
    "        df.loc[df['subject_id'] == subject, MEASUREMENT + '_responder'] = responder\n",
    "        df.loc[df['subject_id'] == subject, MEASUREMENT + '_discriminator'] = discriminator\n",
    "\n",
    "        \n",
    "        \n",
    "# Append baseline measures: \n",
    "\n",
    "df_baseline_anx = pd.read_excel('HR+RMSSD.xls', sheet_name = 'ANXKJP')\n",
    "df_baseline_ges = pd.read_excel('HR+RMSSD.xls', sheet_name = 'GESKJP')\n",
    "\n",
    "\n",
    "df['baseline_HR_Phase1'] = np.NaN\n",
    "df['baseline_RMSSD_Phase1'] = np.NaN\n",
    "\n",
    "for subject in df['subject_id'].unique():\n",
    "    if subject.startswith('ANX'):\n",
    "        # Get baseline values:\n",
    "        baseline_HR = df_baseline_anx.loc[df_baseline_anx['Subject'] == subject, 'HR_Phase1'].values[0]\n",
    "        baseline_RMSSD = df_baseline_anx.loc[df_baseline_anx['Subject'] == subject, 'RMSSD_Phase1'].values[0]\n",
    "        \n",
    "    elif subject.startswith('GES'):\n",
    "        # Get baseline values:\n",
    "        baseline_HR = df_baseline_ges.loc[df_baseline_ges['Subject'] == subject, 'HR_Phase1'].values[0]\n",
    "        baseline_RMSSD = df_baseline_ges.loc[df_baseline_ges['Subject'] == subject, 'RMSSD_Phase1'].values[0]       \n",
    "        \n",
    "    # Copy them to the main DataFrame:\n",
    "    df.loc[df['subject_id'] == subject, 'baseline_HR_Phase1'] = baseline_HR\n",
    "    df.loc[df['subject_id'] == subject, 'baseline_RMSSD_Phase1'] = baseline_RMSSD\n",
    "        \n",
    "if SAVE:\n",
    "    df.to_csv('all_normalized_and_classified_single_data_with_gen1.csv') \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-tradition",
   "metadata": {},
   "source": [
    "## __Option B:__ Read the already preprocessed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_normalized_and_classified_single_data_with_gen1.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-dividend",
   "metadata": {},
   "source": [
    "#### First of, here is an overview of the mean responses from all individual subjects and the mean group response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_TYPE = 'norm_global_CS-'\n",
    "STIM_COUNT = 'session_mean'\n",
    "MEASUREMENT = 'HR'\n",
    "SESSION = 'acq1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-focus",
   "metadata": {},
   "source": [
    "Since this is the first plot, the following cell will setup some features of the figure layout and can be used to change the layout & design of all subsequent figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_SIZE = 15\n",
    "SUBTITLE_SIZE = 13\n",
    "AXES_LABEL_SIZE = 12\n",
    "COLOR_CTRL = 'g'\n",
    "COLOR_ANX = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-preserve",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "df_anx = df.loc[(df['session'] == SESSION) & (df['value_type'] == VALUE_TYPE) & (df['measurement'] == MEASUREMENT) \n",
    "                & (df['stim_count'] == STIM_COUNT) & (df['group'] == 'anxiety')].copy()\n",
    "df_ctrl = df.loc[(df['session'] == SESSION) & (df['value_type'] == VALUE_TYPE) & (df['measurement'] == MEASUREMENT) \n",
    "                & (df['stim_count'] == STIM_COUNT) & (df['group'] == 'control')].copy()\n",
    "\n",
    "mean_anx = df_anx.iloc[:, idx_start:idx_stop].mean()\n",
    "sem_anx = df_anx.iloc[:, idx_start:idx_stop].sem()\n",
    "mean_ctrl = df_ctrl.iloc[:, idx_start:idx_stop].mean()\n",
    "sem_ctrl = df_ctrl.iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "df_ctrl.iloc[:, idx_start:idx_stop].transpose().plot(legend=False, alpha=.2, color=COLOR_CTRL, ax=ax1)\n",
    "plt.errorbar(x = list(mean_ctrl.index), y = mean_ctrl.values, yerr = sem_ctrl.values, color=COLOR_CTRL)\n",
    "plt.title('Control group', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel(VALUE_TYPE, fontsize=AXES_LABEL_SIZE)\n",
    "#plt.ylim(0.25, 0.4)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1], sharey=ax1)\n",
    "df_anx.iloc[:, idx_start:idx_stop].transpose().plot(legend=False, alpha=.2, color=COLOR_ANX, ax=ax2)\n",
    "plt.errorbar(x = list(mean_anx.index), y = mean_anx.values, yerr = sem_anx.values, color=COLOR_ANX)\n",
    "plt.title('Anxiety group', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel(VALUE_TYPE, fontsize=AXES_LABEL_SIZE)\n",
    "\n",
    "plt.suptitle(VALUE_TYPE + ' for ' + MEASUREMENT + ' in session: ' + SESSION, fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-encounter",
   "metadata": {},
   "source": [
    "#### Since each subject receives multiple stimulus presentations per session, we can also plot the response to each presentation individually & compare them to the session mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUBJECT_ID = df['subject_id'].unique()[0]\n",
    "SUBJECT_ID = 'GESKJP016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-spoke",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "df_CSminus = df.loc[(df['session'] == SESSION) & (df['value_type'] == 'norm_global_CS-') & (df['measurement'] == MEASUREMENT) \n",
    "                & (df['stim_count'] != 'session_mean') & (df['subject_id'] == SUBJECT_ID)].copy()\n",
    "df_CSplus = df.loc[(df['session'] == SESSION) & (df['value_type'] == 'norm_global_CS+') & (df['measurement'] == MEASUREMENT) \n",
    "                & (df['stim_count'] != 'session_mean') & (df['subject_id'] == SUBJECT_ID)].copy()\n",
    "\n",
    "mean_CSminus = df_CSminus.iloc[:, idx_start:idx_stop].mean()\n",
    "sem_CSminus = df_CSminus.iloc[:, idx_start:idx_stop].sem()\n",
    "mean_CSplus = df_CSplus.iloc[:, idx_start:idx_stop].mean()\n",
    "sem_CSplus = df_CSplus.iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "group_id = df.loc[df['subject_id'] == SUBJECT_ID, 'group'].iloc[0]\n",
    "\n",
    "if group_id == 'control':\n",
    "    color = COLOR_CTRL\n",
    "elif group_id == 'anxiety':\n",
    "    color = COLOR_ANX\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "df_CSminus.iloc[:, idx_start:idx_stop].transpose().plot(legend=False, alpha=.2, color=color, ax=ax1)\n",
    "plt.errorbar(x = list(mean_CSminus.index), y = mean_CSminus.values, yerr = sem_CSminus.values, color=color)\n",
    "plt.title('Responses to CS-', fontsize = SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize = AXES_LABEL_SIZE)\n",
    "plt.ylabel('norm global CS-', fontsize = AXES_LABEL_SIZE)\n",
    "#plt.ylim(0.25, 0.4)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1], sharey=ax1)\n",
    "df_CSplus.iloc[:, idx_start:idx_stop].transpose().plot(legend=False, alpha=.2, color=color, ax=ax2)\n",
    "plt.errorbar(x = list(mean_CSplus.index), y = mean_CSplus.values, yerr = sem_CSplus.values, color=color)\n",
    "plt.title('Responses to CS+', fontsize = SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize = AXES_LABEL_SIZE)\n",
    "plt.ylabel('norm global CS+', fontsize = AXES_LABEL_SIZE)\n",
    "\n",
    "plt.suptitle(MEASUREMENT + ' responses of ' + SUBJECT_ID + ' in session: ' + SESSION, fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-survey",
   "metadata": {},
   "source": [
    "## Next, let´s inspect the development of responses and the discrimination ratio during the course of the experiment\n",
    "\n",
    "#### For this, we plot all responses for a given measurement and the resulting discrimination ratios across all sessions to get a first overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASUREMENT = 'HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(20, 40))\n",
    "gs = fig.add_gridspec(8, 2)\n",
    "\n",
    "l_sessions = ['preacq', 'acq1', 'acq2', 'gen1', 'gen2', 'ext1', 'ext2', 'ext3']\n",
    "\n",
    "\n",
    "SESSION = 'preacq'\n",
    "\n",
    "# Select data\n",
    "df_ctrl = df.loc[(df['session'] == SESSION) & (df['group'] == 'control') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "df_anx = df.loc[(df['session'] == SESSION) & (df['group'] == 'anxiety') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "\n",
    "anx_norm_cs_p = df_anx.loc[df_anx['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_norm_cs_m = df_anx.loc[df_anx['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_norm_cs_p = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_norm_cs_m = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_disrcim_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "# Create the plots:\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(anx_norm_cs_p, color = COLOR_ANX, alpha = 1, label='anxiety CS+')\n",
    "plt.plot(anx_norm_cs_m, color = COLOR_ANX, alpha = 1, linestyle = 'dashed', label='anxiety CS-')\n",
    "\n",
    "plt.plot(ctrl_norm_cs_p, color = COLOR_CTRL, alpha = 1, label='control CS+')\n",
    "plt.plot(ctrl_norm_cs_m, color = COLOR_CTRL, alpha = 1, linestyle = 'dashed', label='control CS-')\n",
    "#plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color='m', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('normalized CS responses', fontsize=AXES_LABEL_SIZE)\n",
    "plt.title('CS responses during: {}'.format(SESSION), fontsize=SUBTITLE_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "#fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "#plt.title('Control group')\n",
    "#plt.xlabel('time in [s] from stimulus onset')\n",
    "#plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "#plt.legend(loc = 'lower left')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "#fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color=COLOR_ANX, label='anxiety')\n",
    "plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios during: {}'.format(SESSION), fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "\n",
    "for column in range(1,8):\n",
    "    SESSION = l_sessions[column]\n",
    "    \n",
    "    # Select data\n",
    "    df_ctrl = df.loc[(df['session'] == SESSION) & (df['group'] == 'control') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "    df_anx = df.loc[(df['session'] == SESSION) & (df['group'] == 'anxiety') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "\n",
    "    anx_norm_cs_p = df_anx.loc[df_anx['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "    anx_norm_cs_m = df_anx.loc[df_anx['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "    anx_discrim = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "    anx_discrim_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "    ctrl_norm_cs_p = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "    ctrl_norm_cs_m = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "    ctrl_discrim = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "    ctrl_disrcim_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "    \n",
    "\n",
    "    # Create the plots:\n",
    "    fig.add_subplot(gs[column, 0], sharey=ax1)\n",
    "    plt.plot(anx_norm_cs_p, color = COLOR_ANX, alpha = 1, label='anxiety CS+')\n",
    "    plt.plot(anx_norm_cs_m, color = COLOR_ANX, alpha = 1, linestyle = 'dashed', label='anxiety CS-')\n",
    "\n",
    "    plt.plot(ctrl_norm_cs_p, color = COLOR_CTRL, alpha = 1, label='control CS+')\n",
    "    plt.plot(ctrl_norm_cs_m, color = COLOR_CTRL, alpha = 1, linestyle = 'dashed', label='control CS-')\n",
    "    #plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color='m', label='discrim. ratio')\n",
    "    #plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "    plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "    plt.ylabel('normalized CS responses', fontsize=AXES_LABEL_SIZE)\n",
    "    plt.title('CS responses during: {}'.format(SESSION), fontsize=SUBTITLE_SIZE)\n",
    "    plt.legend(loc = 'lower left')\n",
    "\n",
    "    #fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "    #plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "    #plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "    #plt.title('Control group')\n",
    "    #plt.xlabel('time in [s] from stimulus onset')\n",
    "    #plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "    #plt.legend(loc = 'lower left')\n",
    "\n",
    "    fig.add_subplot(gs[column,1], sharey=ax2)\n",
    "    #fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "    plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color=COLOR_ANX, label='anxiety')\n",
    "    plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "    plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "    plt.title('Discrimination ratios during: {}'.format(SESSION), fontsize=SUBTITLE_SIZE)\n",
    "    plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "    plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "    plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-click",
   "metadata": {},
   "source": [
    "## Now let´s do the statistics:\n",
    "\n",
    "#### For this, we plot the group mean responses for a given session & measurement and compare the responses to the two CS and the discrimination ratios\n",
    "\n",
    "`SESSION`: 'preacq', 'acq1', 'acq2', 'gen1', 'gen2', 'ext1', 'ext2', 'ext3' <br>\n",
    "`MEASUREMENT`: 'HR', 'EDA'<br>\n",
    "\n",
    "#### The results of statistical comparisons will be displayed below the plot. A mixed-model-ANOVA (MMA) and the pairwise comparisons for each timepoint will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION = 'ext1' \n",
    "MEASUREMENT = 'HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-quick",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "# Select data\n",
    "df_ctrl = df.loc[(df['session'] == SESSION) & (df['group'] == 'control') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "df_anx = df.loc[(df['session'] == SESSION) & (df['group'] == 'anxiety') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "\n",
    "anx_norm_cs_p = df_anx.loc[df_anx['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_norm_cs_m = df_anx.loc[df_anx['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_norm_cs_p = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_norm_cs_m = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_disrcim_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(anx_norm_cs_p, color = COLOR_ANX, alpha = 1, label='anxiety CS+')\n",
    "plt.plot(anx_norm_cs_m, color = COLOR_ANX, alpha = 1, linestyle = 'dashed', label='anxiety CS-')\n",
    "\n",
    "plt.plot(ctrl_norm_cs_p, color = COLOR_CTRL, alpha = 1, label='control CS+')\n",
    "plt.plot(ctrl_norm_cs_m, color = COLOR_CTRL, alpha = 1, linestyle = 'dashed', label='control CS-')\n",
    "#plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color='m', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('normalized CS responses', fontsize=AXES_LABEL_SIZE)\n",
    "plt.title('CS responses', fontsize=SUBTITLE_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "#fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "#plt.title('Control group')\n",
    "#plt.xlabel('time in [s] from stimulus onset')\n",
    "#plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "#plt.legend(loc = 'lower left')\n",
    "\n",
    "fig.add_subplot(gs[0,1])\n",
    "#fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color=COLOR_ANX, label='anxiety')\n",
    "plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.suptitle(MEASUREMENT + ' in session: ' + SESSION, fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Now also compute the corresponding statistics:\n",
    "\n",
    "VALUE_TYPE = 'discrim_ratio'\n",
    "\n",
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    l_timepoints = [str(elem) for elem in list(range(0, 16))]\n",
    "elif -1 in df.columns:\n",
    "    l_timepoints = list(range(0, 16))\n",
    "\n",
    "l_dfs_per_timepoint = []\n",
    "\n",
    "for timepoint in l_timepoints:\n",
    "    df_temp = df.loc[(df['session'] == SESSION) & (df['value_type'] == 'norm_global_' + VALUE_TYPE) & (df['measurement'] == MEASUREMENT)\n",
    "                     & (df['stim_count'] == 'session_mean'), ['subject_id', 'group', 'measurement', 'session', 'value_type', timepoint]].copy()\n",
    "    l_headers = list(df_temp.columns)\n",
    "    l_headers[-1] = 'data'\n",
    "    df_temp.columns = l_headers\n",
    "    df_temp['timepoint'] = float(timepoint)\n",
    "    l_dfs_per_timepoint.append(df_temp)\n",
    "    \n",
    "df_stats = pd.concat(l_dfs_per_timepoint)\n",
    "\n",
    "results_mixed_anova = pg.mixed_anova(data=df_stats, dv='data', between='group', within='timepoint', subject='subject_id')\n",
    "p_groups, p_timepoints, p_interactions = results_mixed_anova.loc[0,'p-unc'], results_mixed_anova.loc[1,'p-unc'], results_mixed_anova.loc[2,'p-unc']\n",
    "\n",
    "df_pairwise = pg.pairwise_ttests(data=df_stats, dv='data', between='group', within='timepoint', subject='subject_id', padjust='bonf')\n",
    "l_pairwise_p_values = list(df_pairwise.loc[df_pairwise['Contrast'] == 'timepoint * group'].sort_values(by='timepoint').loc[:,'p-unc'].values)\n",
    "\n",
    "p_values_vs_05 = {}\n",
    "for group in ['control', 'anxiety']:\n",
    "    l_p_values_05 = []\n",
    "    for timepoint in range(0, 16):\n",
    "        data = df_stats.loc[(df_stats['group'] == group) & (df_stats['timepoint'] == timepoint), 'data'].values\n",
    "        l_p_values_05.append(round(pg.ttest(x=data, y=0.5).loc['T-test', 'p-val'], 3))\n",
    "    p_values_vs_05[group] = l_p_values_05\n",
    "\n",
    "level1 = ['Mixed-Model-ANOVA', 'Mixed-Model-ANOVA', 'Mixed-Model-ANOVA']\n",
    "level2 = ['Groups', 'Timepoints', 'Interactions']\n",
    "\n",
    "for x in range(16):\n",
    "    level1.append('pairwise comparisons per timepoint')\n",
    "    level2.append(str(x))\n",
    "    \n",
    "tuples = list(zip(*[level1, level2]))\n",
    "index = pd.MultiIndex.from_tuples(tuples)\n",
    "    \n",
    "df_stats_summary = pd.DataFrame(index=['p-values Ctrl vs. Anx', 'p-values Ctrl vs. 0.5', 'p-values Anx vs. 0.5'], columns=index)\n",
    "l_p_values = [p_groups, p_timepoints, p_interactions] + l_pairwise_p_values\n",
    "l_p_values = [round(elem, 3) for elem in l_p_values]\n",
    "\n",
    "df_stats_summary.loc['p-values Ctrl vs. Anx', :] = l_p_values\n",
    "df_stats_summary.iloc[1, 3:] = p_values_vs_05['control']\n",
    "df_stats_summary.iloc[2, 3:] = p_values_vs_05['anxiety']\n",
    "\n",
    "df_stats_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-description",
   "metadata": {},
   "source": [
    "## We can also take a closer look at the responses to the morphed faces during the generalization sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_SESSION = 'gen2'\n",
    "MEASUREMENT = 'HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-netherlands",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "# Select data\n",
    "df_ctrl = df.loc[(df['session'] == GEN_SESSION) & (df['group'] == 'control') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "df_anx = df.loc[(df['session'] == GEN_SESSION) & (df['group'] == 'anxiety') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "\n",
    "\n",
    "anx_discrim = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "anx_discrim_GS1 = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_GS1_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "anx_discrim_GS2 = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_GS2_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "anx_discrim_GS3 = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_GS3_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "anx_discrim_GS4 = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_GS4_sem = df_anx.loc[df_anx['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "ctrl_discrim = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_discrim_GS1 = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_GS1_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_discrim_GS2 = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_GS2_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_discrim_GS3 = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_GS3_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_discrim_GS4 = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_GS4_sem = df_ctrl.loc[df_ctrl['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_discrim_sem.values, color=COLOR_CTRL, label='CS-')\n",
    "plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim_GS1.values, yerr = ctrl_discrim_GS1_sem.values, color=COLOR_CTRL, label='GS1', alpha=0.8)\n",
    "plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim_GS2.values, yerr = ctrl_discrim_GS2_sem.values, color=COLOR_CTRL, label='GS2', alpha=0.6)\n",
    "plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim_GS3.values, yerr = ctrl_discrim_GS3_sem.values, color=COLOR_CTRL, label='GS3', alpha=0.4)\n",
    "plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim_GS4.values, yerr = ctrl_discrim_GS4_sem.values, color=COLOR_CTRL, label='GS4', alpha=0.2)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - control group', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "#fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "#plt.title('Control group')\n",
    "#plt.xlabel('time in [s] from stimulus onset')\n",
    "#plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "#plt.legend(loc = 'lower left')\n",
    "\n",
    "fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "#fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color=COLOR_ANX, label='CS-')\n",
    "plt.errorbar(x = list(anx_discrim.index), y = anx_discrim_GS1.values, yerr = anx_discrim_GS1_sem.values, color=COLOR_ANX, label='GS1', alpha=0.8)\n",
    "plt.errorbar(x = list(anx_discrim.index), y = anx_discrim_GS2.values, yerr = anx_discrim_GS2_sem.values, color=COLOR_ANX, label='GS2', alpha=0.6)\n",
    "plt.errorbar(x = list(anx_discrim.index), y = anx_discrim_GS3.values, yerr = anx_discrim_GS3_sem.values, color=COLOR_ANX, label='GS3', alpha=0.4)\n",
    "plt.errorbar(x = list(anx_discrim.index), y = anx_discrim_GS4.values, yerr = anx_discrim_GS4_sem.values, color=COLOR_ANX, label='GS4', alpha=0.2)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - anxiety group', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.suptitle(MEASUREMENT + ' in session: ' + GEN_SESSION, fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-scholarship",
   "metadata": {},
   "source": [
    "# __GS stimuli anschauen anstatt Discrim ratio__ 2 x 2 plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-convert",
   "metadata": {},
   "source": [
    "## Likewise, we can check how the responses develop in the extinction sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASUREMENT = 'HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-original",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "# Select data\n",
    "df_ctrl_1 = df.loc[(df['session'] == 'ext1') & (df['group'] == 'control') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "df_anx_1 = df.loc[(df['session'] == 'ext1') & (df['group'] == 'anxiety') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "\n",
    "df_ctrl_2 = df.loc[(df['session'] == 'ext2') & (df['group'] == 'control') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "df_anx_2 = df.loc[(df['session'] == 'ext2') & (df['group'] == 'anxiety') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "\n",
    "df_ctrl_3 = df.loc[(df['session'] == 'ext3') & (df['group'] == 'control') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "df_anx_3 = df.loc[(df['session'] == 'ext3') & (df['group'] == 'anxiety') & (df['measurement'] == MEASUREMENT)].copy()\n",
    "\n",
    "\n",
    "ctrl_discrim_1 = df_ctrl_1.loc[df_ctrl_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_sem_1 = df_ctrl_1.loc[df_ctrl_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_discrim_2 = df_ctrl_2.loc[df_ctrl_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_sem_2 = df_ctrl_2.loc[df_ctrl_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "ctrl_discrim_3 = df_ctrl_3.loc[df_ctrl_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "ctrl_discrim_sem_3 = df_ctrl_3.loc[df_ctrl_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "anx_discrim_1 = df_anx_1.loc[df_anx_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_sem_1 = df_anx_1.loc[df_anx_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "anx_discrim_2 = df_anx_2.loc[df_anx_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_sem_2 = df_anx_2.loc[df_anx_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "anx_discrim_3 = df_anx_3.loc[df_anx_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "anx_discrim_sem_3 = df_anx_3.loc[df_anx_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "plt.errorbar(x = list(ctrl_discrim_1.index), y = ctrl_discrim_1.values, yerr = ctrl_discrim_sem_1.values, color=COLOR_CTRL, label='Ext1')\n",
    "plt.errorbar(x = list(ctrl_discrim_2.index), y = ctrl_discrim_2.values, yerr = ctrl_discrim_sem_2.values, color=COLOR_CTRL, label='Ext2', alpha=0.7)\n",
    "plt.errorbar(x = list(ctrl_discrim_3.index), y = ctrl_discrim_3.values, yerr = ctrl_discrim_sem_3.values, color=COLOR_CTRL, label='Ext3', alpha=0.4)\n",
    "\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - control group', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "#fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "#plt.title('Control group')\n",
    "#plt.xlabel('time in [s] from stimulus onset')\n",
    "#plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "#plt.legend(loc = 'lower left')\n",
    "\n",
    "fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "#fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "plt.errorbar(x = list(anx_discrim_1.index), y = anx_discrim_1.values, yerr = anx_discrim_sem_1.values, color=COLOR_ANX, label='Ext1')\n",
    "plt.errorbar(x = list(anx_discrim_2.index), y = anx_discrim_2.values, yerr = anx_discrim_sem_2.values, color=COLOR_ANX, label='Ext2', alpha=0.7)\n",
    "plt.errorbar(x = list(anx_discrim_3.index), y = anx_discrim_3.values, yerr = anx_discrim_sem_3.values, color=COLOR_ANX, label='Ext3', alpha=0.4)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - anxiety group', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.suptitle(MEASUREMENT + ' in session: Ext1-3', fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-google",
   "metadata": {},
   "source": [
    "## Baseline measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-trial",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_individual_subjects = df.loc[(df['measurement'] == 'EDA') & (df['value_type'] == 'abs_CS-') & (df['session'] == 'preacq') & (df['stim_count'] == '1')].copy()\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8), facecolor='white')\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "dv = 'baseline_HR_Phase1'\n",
    "group = 'group'\n",
    "\n",
    "df_normality = pg.normality(df_individual_subjects, dv=dv, group=group)\n",
    "df_equal_var = pg.homoscedasticity(df_individual_subjects, dv=dv, group=group)\n",
    "\n",
    "if (df_normality.iloc[0,1] > 0.05) & (df_normality.iloc[1,1] > 0.05) & (df_equal_var.iloc[0,1] > 0.05):\n",
    "    # parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'control', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'anxiety', dv].values\n",
    "    df_stats = pg.ttest(x, y)\n",
    "    p_val = df_stats['p-val']['T-test']\n",
    "    \n",
    "else:\n",
    "    # non-parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'control', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'anxiety', dv].values\n",
    "    df_stats = pg.mwu(x, y)\n",
    "    p_val = df_stats['p-val']['MWU']\n",
    "    \n",
    "sns.swarmplot(data=df_individual_subjects, x=group, y=dv, ax=f_ax1, palette=['g', 'm'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('heart rate [bpm]')\n",
    "plt.ylim(0)\n",
    "\n",
    "if p_val > 0.05:\n",
    "    title = 'Heart rates are not significantly different (p = {})'.format(str(round(p_val, 4)))  \n",
    "else:\n",
    "    title = 'Heart rates are significantly different (p = {})'.format(str(round(p_val, 4)))\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "\n",
    "f_ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "dv = 'baseline_RMSSD_Phase1'\n",
    "group = 'group'\n",
    "\n",
    "df_normality = pg.normality(df_individual_subjects, dv=dv, group=group)\n",
    "df_equal_var = pg.homoscedasticity(df_individual_subjects, dv=dv, group=group)\n",
    "\n",
    "if (df_normality.iloc[0,1] > 0.05) & (df_normality.iloc[1,1] > 0.05) & (df_equal_var.iloc[0,1] > 0.05):\n",
    "    # parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'control', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'anxiety', dv].values\n",
    "    df_stats = pg.ttest(x, y)\n",
    "    p_val = df_stats['p-val']['T-test']\n",
    "    \n",
    "else:\n",
    "    # non-parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'control', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'anxiety', dv].values\n",
    "    df_stats = pg.mwu(x, y)\n",
    "    p_val = df_stats['p-val']['MWU']\n",
    "    \n",
    "sns.swarmplot(data=df_individual_subjects, x=group, y=dv, ax=f_ax2, palette=['g', 'm'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('RMSSD')\n",
    "plt.ylim(0)\n",
    "\n",
    "if p_val > 0.05:\n",
    "    title = 'RMSSDs are not significantly different (p = {})'.format(str(round(p_val, 4)))  \n",
    "else:\n",
    "    title = 'RMSSDs are significantly different (p = {})'.format(str(round(p_val, 4)))\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-practice",
   "metadata": {},
   "source": [
    "## __Moreover, we also have the Responder & Discriminator classifications__\n",
    "\n",
    "#### In a first go, let´s check for the distribution of responders & discriminator subjects within the two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-glenn",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_proportions = pd.DataFrame(index=['perc_HR_responder', 'perc_HR_discriminator', 'perc_EDA_responder', \n",
    "                                    'perc_EDA_discriminator', 'perc_HR_EDA_responder', 'perc_HR_EDA_discriminator',\n",
    "                                    'perc_no_responder', 'perc_no_discriminator'],\n",
    "                             columns=['control', 'anxiety'])\n",
    "\n",
    "for group in ['control', 'anxiety']:\n",
    "    all_subjects = len(df.loc[df['group'] == group, 'subject_id'].unique())\n",
    "    \n",
    "    perc_HR_responder = (len(df.loc[(df['group'] == group) & (df['HR_responder'] == True) & (df['EDA_responder'] == False), 'subject_id'].unique()) / all_subjects) * 100\n",
    "    perc_HR_discriminator = (len(df.loc[(df['group'] == group) & (df['HR_discriminator'] == True)  & (df['EDA_discriminator'] == False), 'subject_id'].unique()) / all_subjects) * 100\n",
    "    \n",
    "    perc_EDA_responder = (len(df.loc[(df['group'] == group) & (df['EDA_responder'] == True)  & (df['HR_responder'] == False), 'subject_id'].unique()) / all_subjects) * 100\n",
    "    perc_EDA_discriminator = (len(df.loc[(df['group'] == group) & (df['EDA_discriminator'] == True) & (df['HR_discriminator'] == False), 'subject_id'].unique()) / all_subjects) * 100\n",
    "    \n",
    "    perc_HR_and_EDA_responder = (len(df.loc[(df['group'] == group) & (df['EDA_responder'] == True)  & (df['HR_responder'] == True), 'subject_id'].unique()) / all_subjects) * 100\n",
    "    perc_HR_and_EDA_discriminator = (len(df.loc[(df['group'] == group) & (df['EDA_discriminator'] == True) & (df['HR_discriminator'] == True), 'subject_id'].unique()) / all_subjects) * 100\n",
    "    \n",
    "    perc_no_responder = (len(df.loc[(df['group'] == group) & (df['EDA_responder'] == False)  & (df['HR_responder'] == False), 'subject_id'].unique()) / all_subjects) * 100\n",
    "    perc_no_discriminator = (len(df.loc[(df['group'] == group) & (df['EDA_discriminator'] == False) & (df['HR_discriminator'] == False), 'subject_id'].unique()) / all_subjects) * 100\n",
    "      \n",
    "    \n",
    "    df_proportions[group] = [perc_HR_responder, perc_HR_discriminator, perc_EDA_responder, perc_EDA_discriminator, \n",
    "                             perc_HR_and_EDA_responder, perc_HR_and_EDA_discriminator, perc_no_responder, perc_no_discriminator]\n",
    "\n",
    "df_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-settle",
   "metadata": {},
   "source": [
    "#### We can also plot these results and inspect the distributions visually.\n",
    "Seems like the predominant (only) difference between the control and anxiety group is that there is a significant proportion of HR_discriminators \"missing\" in the anxiety group, which also leads to a larger proportion of subjects that are classified as no discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-concept",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dict_for_chi_square = {'responder': {},\n",
    "                      'discriminator': {}}\n",
    "\n",
    "for group in ['control', 'anxiety']:\n",
    "\n",
    "    N_HR_responder = len(df.loc[(df['group'] == group) & (df['HR_responder'] == True) & (df['EDA_responder'] == False), 'subject_id'].unique())\n",
    "    N_HR_discriminator = len(df.loc[(df['group'] == group) & (df['HR_discriminator'] == True)  & (df['EDA_discriminator'] == False), 'subject_id'].unique())\n",
    "\n",
    "    N_EDA_responder = len(df.loc[(df['group'] == group) & (df['EDA_responder'] == True)  & (df['HR_responder'] == False), 'subject_id'].unique())\n",
    "    N_EDA_discriminator = len(df.loc[(df['group'] == group) & (df['EDA_discriminator'] == True) & (df['HR_discriminator'] == False), 'subject_id'].unique())\n",
    "\n",
    "    N_HR_and_EDA_responder = len(df.loc[(df['group'] == group) & (df['EDA_responder'] == True)  & (df['HR_responder'] == True), 'subject_id'].unique())\n",
    "    N_HR_and_EDA_discriminator = len(df.loc[(df['group'] == group) & (df['EDA_discriminator'] == True) & (df['HR_discriminator'] == True), 'subject_id'].unique())\n",
    "\n",
    "    N_no_responder = len(df.loc[(df['group'] == group) & (df['EDA_responder'] == False)  & (df['HR_responder'] == False), 'subject_id'].unique())\n",
    "    N_no_discriminator = len(df.loc[(df['group'] == group) & (df['EDA_discriminator'] == False) & (df['HR_discriminator'] == False), 'subject_id'].unique())\n",
    "    \n",
    "    dict_for_chi_square['responder'][group] = [N_HR_responder, N_EDA_responder, N_HR_and_EDA_responder, N_no_responder]\n",
    "    dict_for_chi_square['discriminator'][group] = [N_HR_discriminator, N_EDA_discriminator, N_HR_and_EDA_discriminator, N_no_discriminator]\n",
    "\n",
    "pval = stats.chi2_contingency([dict_for_chi_square[TYPE]['control'], dict_for_chi_square[TYPE]['anxiety']])[1]\n",
    "\n",
    "if pval > 0.05:\n",
    "    significance = 'not significantly'\n",
    "else:\n",
    "    significance = 'significantly'\n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize=(25,15), facecolor='white')\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "fig.add_subplot(gs[0,0])\n",
    "\n",
    "group = 'control'\n",
    "HR_only = round(df_proportions.loc['perc_HR_' + TYPE, group], 2)\n",
    "EDA_only = round(df_proportions.loc['perc_EDA_' + TYPE, group], 2)\n",
    "HR_and_EDA = round(df_proportions.loc['perc_HR_EDA_' + TYPE, group], 2)\n",
    "No = round(df_proportions.loc['perc_no_' + TYPE, group], 2)\n",
    "\n",
    "vd = venn3(subsets = (HR_only, EDA_only, HR_and_EDA, No, 0, 0, 0), set_labels = ('HR ' + TYPE, 'EDA ' + TYPE, 'No  ' + TYPE), alpha = 0.75, set_colors=('darkorange', 'dodgerblue', 'red'))\n",
    "\n",
    "lbl_a = vd.get_label_by_id(\"A\")\n",
    "x_a, y_a = lbl_a.get_position()\n",
    "lbl_a.set_position((x_a-0.15, y_a-0.03))\n",
    "\n",
    "lbl_b = vd.get_label_by_id(\"B\")\n",
    "x_b, y_b = lbl_b.get_position()\n",
    "lbl_b.set_position((x_b+0.1, y_a+0.02))\n",
    "\n",
    "plt.title('Percentage of ' + TYPE + 's among control subjects', fontsize=TITLE_SIZE)\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "\n",
    "group = 'anxiety'\n",
    "HR_only = round(df_proportions.loc['perc_HR_' + TYPE, group], 2)\n",
    "EDA_only = round(df_proportions.loc['perc_EDA_' + TYPE, group], 2)\n",
    "HR_and_EDA = round(df_proportions.loc['perc_HR_EDA_' + TYPE, group], 2)\n",
    "No = round(df_proportions.loc['perc_no_' + TYPE, group], 2)\n",
    "\n",
    "\n",
    "vd = venn3(subsets = (HR_only, EDA_only, HR_and_EDA, No, 0, 0, 0), set_labels = ('HR ' + TYPE, 'EDA ' + TYPE, 'No  ' + TYPE), alpha = 0.75, set_colors=('darkorange', 'dodgerblue', 'red'))\n",
    "\n",
    "lbl_a = vd.get_label_by_id(\"A\")\n",
    "x_a, y_a = lbl_a.get_position()\n",
    "lbl_a.set_position((x_a-0.15, y_a))\n",
    "\n",
    "lbl_b = vd.get_label_by_id(\"B\")\n",
    "x_b, y_b = lbl_b.get_position()\n",
    "lbl_b.set_position((x_b+0.1, y_a-0.05))\n",
    "\n",
    "plt.title('Percentage of ' + TYPE + 's among anxiety subjects', fontsize=TITLE_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "text = 'Proportions are ' + significance + ' different between the two groups (p = ' + str(round(pval, 4)) + ')'\n",
    "\n",
    "plt.text(x=-2.1, y=-0.7, s=text, fontsize=TITLE_SIZE+3)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-luxembourg",
   "metadata": {},
   "source": [
    "### Are there actually correlations between being a HR and being a EDA responder (or discriminator)?\n",
    "\n",
    "Let´s quickly screen all possibilities that exist for significant results (at given significance and power-level thresholds). Following this screening cell, there is a piece of code that let´s you check any combination in more details. Possible \"warnings\" can arise if the respective group combination occurs less than five times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The screening will only output those combinations where the p-value was lower or equal to PVAL:\n",
    "PVAL = 0.05\n",
    "\n",
    "# The screening will only output those combinations where the power was larger than POWER:\n",
    "POWER = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-elizabeth",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_individual_subjects = df.loc[(df['measurement'] == 'EDA') & (df['value_type'] == 'abs_CS-') & (df['session'] == 'preacq') & (df['stim_count'] == '1')].iloc[:, :10].copy()\n",
    "\n",
    "df_responders = df_individual_subjects.loc[(df_individual_subjects['HR_responder'] == True) | (df_individual_subjects['HR_discriminator'] == True) | \n",
    "                                                  (df_individual_subjects['EDA_responder'] == True) | (df_individual_subjects['EDA_discriminator'] == True)].copy()\n",
    "\n",
    "df_non_responders = df_individual_subjects.loc[(df_individual_subjects['HR_responder'] == False) & (df_individual_subjects['HR_discriminator'] == False) & \n",
    "                                                  (df_individual_subjects['EDA_responder'] == False) & (df_individual_subjects['EDA_discriminator'] == False)].copy()\n",
    "\n",
    "l_significant_results = []\n",
    "\n",
    "for assigned_groups_to_check in ['both', 'control only', 'anxiety only']:\n",
    "    for responder_types_to_check in ['all', 'responders only', 'non-responders only']:\n",
    "        for classification_type in ['responder', 'discriminator']:\n",
    "            \n",
    "            df_temp = [df_individual_subjects, df_responders, df_non_responders][['all', 'responders only', 'non-responders only'].index(responder_types_to_check)]\n",
    "\n",
    "            all_chi_resp = pg.chi2_independence(data=df_temp, x='HR_responder', y='EDA_responder', correction=True)\n",
    "            all_chi_discrim = pg.chi2_independence(data=df_temp, x='HR_discriminator', y='EDA_discriminator', correction=True)\n",
    "\n",
    "            anx_chi_resp = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'anxiety'], x='HR_responder', y='EDA_responder', correction=True)\n",
    "            anx_chi_discrim = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'anxiety'], x='HR_discriminator', y='EDA_discriminator', correction=True)\n",
    "\n",
    "            ctrl_chi_resp = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'control'], x='HR_responder', y='EDA_responder', correction=True)\n",
    "            ctrl_chi_discrim = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'control'], x='HR_discriminator', y='EDA_discriminator', correction=True)\n",
    "\n",
    "            if classification_type == 'responder':\n",
    "                results = [all_chi_resp, ctrl_chi_resp, anx_chi_resp][['both', 'control only', 'anxiety only'].index(assigned_groups_to_check)]\n",
    "            elif classification_type == 'discriminator':\n",
    "                results = [all_chi_discrim, ctrl_chi_discrim, anx_chi_discrim][['both', 'control only', 'anxiety only'].index(assigned_groups_to_check)]\n",
    "                \n",
    "            if (results[2]['pval'][0] <= PVAL) & (results[2]['power'][0] >= POWER):\n",
    "                l_significant_results.append((assigned_groups_to_check, responder_types_to_check, classification_type))\n",
    "\n",
    "l_significant_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify, whether the analysis should be performed only for a specific group\n",
    "# Chose one of: ['both', 'control only', 'anxiety only']\n",
    "assigned_groups_to_check = 'anxiety only'\n",
    "\n",
    "# Please specify, whether only responders or non-responders should be analyzed, or whether you want to consider all subjects\n",
    "# Chose one of: ['all', 'responders only', 'non-repsonders only']\n",
    "responder_types_to_check = 'responders only'\n",
    "\n",
    "# Finally, please specify, whether you want to check for correelations among responders or discriminators\n",
    "# Chose one of: ['responder', 'discriminator']\n",
    "classification_type = 'discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-array",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_individual_subjects = df.loc[(df['measurement'] == 'EDA') & (df['value_type'] == 'abs_CS-') & (df['session'] == 'preacq') & (df['stim_count'] == '1')].iloc[:, :10].copy()\n",
    "\n",
    "df_responders = df_individual_subjects.loc[(df_individual_subjects['HR_responder'] == True) | (df_individual_subjects['HR_discriminator'] == True) | \n",
    "                                                  (df_individual_subjects['EDA_responder'] == True) | (df_individual_subjects['EDA_discriminator'] == True)].copy()\n",
    "\n",
    "df_non_responders = df_individual_subjects.loc[(df_individual_subjects['HR_responder'] == False) & (df_individual_subjects['HR_discriminator'] == False) & \n",
    "                                                  (df_individual_subjects['EDA_responder'] == False) & (df_individual_subjects['EDA_discriminator'] == False)].copy()\n",
    "\n",
    "df_temp = [df_individual_subjects, df_responders, df_non_responders][['all', 'responders only', 'non-responders only'].index(responder_types_to_check)]\n",
    "\n",
    "all_chi_resp = pg.chi2_independence(data=df_temp, x='HR_responder', y='EDA_responder', correction=True)\n",
    "all_chi_discrim = pg.chi2_independence(data=df_temp, x='HR_discriminator', y='EDA_discriminator', correction=True)\n",
    "\n",
    "anx_chi_resp = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'anxiety'], x='HR_responder', y='EDA_responder', correction=True)\n",
    "anx_chi_discrim = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'anxiety'], x='HR_discriminator', y='EDA_discriminator', correction=True)\n",
    "\n",
    "ctrl_chi_resp = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'control'], x='HR_responder', y='EDA_responder', correction=True)\n",
    "ctrl_chi_discrim = pg.chi2_independence(data=df_temp.loc[df_temp['group'] == 'control'], x='HR_discriminator', y='EDA_discriminator', correction=True)\n",
    "\n",
    "if classification_type == 'responder':\n",
    "    results = [all_chi_resp, ctrl_chi_resp, anx_chi_resp][['both', 'control only', 'anxiety only'].index(assigned_groups_to_check)]\n",
    "elif classification_type == 'discriminator':\n",
    "    results = [all_chi_discrim, ctrl_chi_discrim, anx_chi_discrim][['both', 'control only', 'anxiety only'].index(assigned_groups_to_check)]\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-identity",
   "metadata": {},
   "source": [
    "## We can now also compare the responses between different groups of responders / discriminators, ignoring original group assignments (i.e. control / anxiety):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP1 = {'HR_responder': True,\n",
    "          'HR_discriminator': True, \n",
    "          'EDA_responder': False,\n",
    "          'EDA_discriminator': False,\n",
    "          'color': 'darkorange'}\n",
    "\n",
    "GROUP2 = {'HR_responder': False,\n",
    "          'HR_discriminator': False, \n",
    "          'EDA_responder': True,\n",
    "          'EDA_discriminator': True,\n",
    "          'color': 'dodgerblue'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION = 'acq2' \n",
    "MEASUREMENT = 'EDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-kingston",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "# Select data\n",
    "df_grp1 = df.loc[(df['session'] == SESSION) & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP1['HR_responder']) & (df['HR_discriminator'] == GROUP1['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP1['EDA_responder']) & (df['EDA_discriminator'] == GROUP1['EDA_discriminator'])].copy()\n",
    "\n",
    "\n",
    "df_grp2 = df.loc[(df['session'] == SESSION) & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP2['HR_responder']) & (df['HR_discriminator'] == GROUP2['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP2['EDA_responder']) & (df['EDA_discriminator'] == GROUP2['EDA_discriminator'])].copy()\n",
    "\n",
    "\n",
    "\n",
    "grp1_norm_cs_p = df_grp1.loc[df_grp1['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_norm_cs_m = df_grp1.loc[df_grp1['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_sem = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp2_norm_cs_p = df_grp2.loc[df_grp2['value_type'] == 'norm_global_CS+'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_norm_cs_m = df_grp2.loc[df_grp2['value_type'] == 'norm_global_CS-'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_sem = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(grp1_norm_cs_p, color = GROUP1['color'], alpha = 1, label='Group 1 CS+')\n",
    "plt.plot(grp1_norm_cs_m, color = GROUP1['color'], alpha = 1, linestyle = 'dashed', label='Group 1 CS-')\n",
    "\n",
    "plt.plot(grp2_norm_cs_p, color = GROUP2['color'], alpha = 1, label='Group 2 CS+')\n",
    "plt.plot(grp2_norm_cs_m, color = GROUP2['color'], alpha = 1, linestyle = 'dashed', label='Group 2 CS-')\n",
    "#plt.errorbar(x = list(anx_discrim.index), y = anx_discrim.values, yerr = anx_discrim_sem.values, color='m', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('normalized CS responses', fontsize=AXES_LABEL_SIZE)\n",
    "plt.title('CS responses', fontsize=SUBTITLE_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "#fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "#plt.title('Control group')\n",
    "#plt.xlabel('time in [s] from stimulus onset')\n",
    "#plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "#plt.legend(loc = 'lower left')\n",
    "\n",
    "fig.add_subplot(gs[0,1])\n",
    "#fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "plt.errorbar(x = list(grp1_discrim.index), y = grp1_discrim.values, yerr = grp1_discrim_sem.values, color=GROUP1['color'], label='Group 1')\n",
    "plt.errorbar(x = list(grp2_discrim.index), y = grp2_discrim.values, yerr = grp2_discrim_sem.values, color=GROUP2['color'], label='Group 2')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.suptitle(MEASUREMENT + ' in session: ' + SESSION, fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Now also compute the corresponding statistics:\n",
    "\n",
    "VALUE_TYPE = 'discrim_ratio'\n",
    "\n",
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    l_timepoints = [str(elem) for elem in list(range(0, 16))]\n",
    "elif -1 in df.columns:\n",
    "    l_timepoints = list(range(0, 16))\n",
    "\n",
    "l_dfs_per_timepoint = []\n",
    "\n",
    "df_grp1['group'] = 'group 1'\n",
    "df_grp2['group'] = 'group 2'\n",
    "\n",
    "df_both_groups = pd.concat([df_grp1, df_grp2])\n",
    "\n",
    "for timepoint in l_timepoints:\n",
    "    df_temp = df_both_groups.loc[(df_both_groups['session'] == SESSION) & (df_both_groups['value_type'] == 'norm_global_' + VALUE_TYPE) \n",
    "                                 & (df_both_groups['measurement'] == MEASUREMENT) & (df_both_groups['stim_count'] == 'session_mean'), \n",
    "                                 ['subject_id', 'group', 'measurement', 'session', 'value_type', timepoint]].copy()\n",
    "    l_headers = list(df_temp.columns)\n",
    "    l_headers[-1] = 'data'\n",
    "    df_temp.columns = l_headers\n",
    "    df_temp['timepoint'] = float(timepoint)\n",
    "    l_dfs_per_timepoint.append(df_temp)\n",
    "    \n",
    "df_stats = pd.concat(l_dfs_per_timepoint)\n",
    "\n",
    "results_mixed_anova = pg.mixed_anova(data=df_stats, dv='data', between='group', within='timepoint', subject='subject_id')\n",
    "p_groups, p_timepoints, p_interactions = results_mixed_anova.loc[0,'p-unc'], results_mixed_anova.loc[1,'p-unc'], results_mixed_anova.loc[2,'p-unc']\n",
    "\n",
    "df_pairwise = pg.pairwise_ttests(data=df_stats, dv='data', between='group', within='timepoint', subject='subject_id', padjust='bonf')\n",
    "l_pairwise_p_values = list(df_pairwise.loc[df_pairwise['Contrast'] == 'timepoint * group'].sort_values(by='timepoint').loc[:,'p-unc'].values)\n",
    "\n",
    "p_values_vs_05 = {}\n",
    "for group in ['group 1', 'group 2']:\n",
    "    l_p_values_05 = []\n",
    "    for timepoint in range(0, 16):\n",
    "        data = df_stats.loc[(df_stats['group'] == group) & (df_stats['timepoint'] == timepoint), 'data'].values\n",
    "        l_p_values_05.append(round(pg.ttest(x=data, y=0.5).loc['T-test', 'p-val'], 3))\n",
    "    p_values_vs_05[group] = l_p_values_05\n",
    "\n",
    "level1 = ['Mixed-Model-ANOVA', 'Mixed-Model-ANOVA', 'Mixed-Model-ANOVA']\n",
    "level2 = ['Groups', 'Timepoints', 'Interactions']\n",
    "\n",
    "for x in range(16):\n",
    "    level1.append('pairwise comparisons per timepoint')\n",
    "    level2.append(str(x))\n",
    "    \n",
    "tuples = list(zip(*[level1, level2]))\n",
    "index = pd.MultiIndex.from_tuples(tuples)\n",
    "    \n",
    "df_stats_summary = pd.DataFrame(index=['p-values Grp1 vs. Grp2', 'p-values Grp1 vs. 0.5', 'p-values Grp2 vs. 0.5'], columns=index)\n",
    "l_p_values = [p_groups, p_timepoints, p_interactions] + l_pairwise_p_values\n",
    "l_p_values = [round(elem, 3) for elem in l_p_values]\n",
    "\n",
    "df_stats_summary.loc['p-values Grp1 vs. Grp2', :] = l_p_values\n",
    "df_stats_summary.iloc[1, 3:] = p_values_vs_05['group 1']\n",
    "df_stats_summary.iloc[2, 3:] = p_values_vs_05['group 2']\n",
    "\n",
    "df_stats_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-robertson",
   "metadata": {},
   "source": [
    "## Similarly, we can also reproduce the generalization and extinction plots with these new group assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_SESSION = 'gen1'\n",
    "MEASUREMENT = 'HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "# Select data\n",
    "df_grp1 = df.loc[(df['session'] == GEN_SESSION) & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP1['HR_responder']) & (df['HR_discriminator'] == GROUP1['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP1['EDA_responder']) & (df['EDA_discriminator'] == GROUP1['EDA_discriminator'])].copy()\n",
    "\n",
    "\n",
    "df_grp2 = df.loc[(df['session'] == GEN_SESSION) & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP2['HR_responder']) & (df['HR_discriminator'] == GROUP2['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP2['EDA_responder']) & (df['EDA_discriminator'] == GROUP2['EDA_discriminator'])].copy()\n",
    "\n",
    "\n",
    "\n",
    "grp1_discrim = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_sem = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp1_discrim_GS1 = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_GS1_sem = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp1_discrim_GS2 = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_GS2_sem = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp1_discrim_GS3 = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_GS3_sem = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp1_discrim_GS4 = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_GS4_sem = df_grp1.loc[df_grp1['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "grp2_discrim = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_sem = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp2_discrim_GS1 = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_GS1_sem = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS1'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp2_discrim_GS2 = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_GS2_sem = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS2'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp2_discrim_GS3 = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_GS3_sem = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS3'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp2_discrim_GS4 = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_GS4_sem = df_grp2.loc[df_grp2['value_type'] == 'norm_global_discrim_ratio_GS4'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "plt.errorbar(x = list(grp1_discrim.index), y = grp1_discrim.values, yerr = grp1_discrim_sem.values, color=GROUP1['color'], label='CS-')\n",
    "plt.errorbar(x = list(grp1_discrim.index), y = grp1_discrim_GS1.values, yerr = grp1_discrim_GS1_sem.values, color=GROUP1['color'], label='GS1', alpha=0.8)\n",
    "plt.errorbar(x = list(grp1_discrim.index), y = grp1_discrim_GS2.values, yerr = grp1_discrim_GS2_sem.values, color=GROUP1['color'], label='GS2', alpha=0.6)\n",
    "plt.errorbar(x = list(grp1_discrim.index), y = grp1_discrim_GS3.values, yerr = grp1_discrim_GS3_sem.values, color=GROUP1['color'], label='GS3', alpha=0.4)\n",
    "plt.errorbar(x = list(grp1_discrim.index), y = grp1_discrim_GS4.values, yerr = grp1_discrim_GS4_sem.values, color=GROUP1['color'], label='GS4', alpha=0.2)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - group1', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "#fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "#plt.title('Control group')\n",
    "#plt.xlabel('time in [s] from stimulus onset')\n",
    "#plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "#plt.legend(loc = 'lower left')\n",
    "\n",
    "fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "#fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "plt.errorbar(x = list(grp2_discrim.index), y = grp2_discrim.values, yerr = grp2_discrim_sem.values, color=GROUP2['color'], label='CS-')\n",
    "plt.errorbar(x = list(grp2_discrim.index), y = grp2_discrim_GS1.values, yerr = grp2_discrim_GS1_sem.values, color=GROUP2['color'], label='GS1', alpha=0.8)\n",
    "plt.errorbar(x = list(grp2_discrim.index), y = grp2_discrim_GS2.values, yerr = grp2_discrim_GS2_sem.values, color=GROUP2['color'], label='GS2', alpha=0.6)\n",
    "plt.errorbar(x = list(grp2_discrim.index), y = grp2_discrim_GS3.values, yerr = grp2_discrim_GS3_sem.values, color=GROUP2['color'], label='GS3', alpha=0.4)\n",
    "plt.errorbar(x = list(grp2_discrim.index), y = grp2_discrim_GS4.values, yerr = grp2_discrim_GS4_sem.values, color=GROUP2['color'], label='GS4', alpha=0.2)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - group2', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.suptitle(MEASUREMENT + ' in session: ' + GEN_SESSION, fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASUREMENT = 'HR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-aquarium",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "# Select data\n",
    "df_grp1_1 = df.loc[(df['session'] == 'ext1') & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP1['HR_responder']) & (df['HR_discriminator'] == GROUP1['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP1['EDA_responder']) & (df['EDA_discriminator'] == GROUP1['EDA_discriminator'])].copy()\n",
    "\n",
    "df_grp1_2 = df.loc[(df['session'] == 'ext2') & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP1['HR_responder']) & (df['HR_discriminator'] == GROUP1['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP1['EDA_responder']) & (df['EDA_discriminator'] == GROUP1['EDA_discriminator'])].copy()\n",
    "\n",
    "df_grp1_3 = df.loc[(df['session'] == 'ext3') & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP1['HR_responder']) & (df['HR_discriminator'] == GROUP1['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP1['EDA_responder']) & (df['EDA_discriminator'] == GROUP1['EDA_discriminator'])].copy()\n",
    "\n",
    "\n",
    "\n",
    "df_grp2_1 = df.loc[(df['session'] == 'ext1') & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP2['HR_responder']) & (df['HR_discriminator'] == GROUP2['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP2['EDA_responder']) & (df['EDA_discriminator'] == GROUP2['EDA_discriminator'])].copy()\n",
    "\n",
    "df_grp2_2 = df.loc[(df['session'] == 'ext2') & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP2['HR_responder']) & (df['HR_discriminator'] == GROUP2['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP2['EDA_responder']) & (df['EDA_discriminator'] == GROUP2['EDA_discriminator'])].copy()\n",
    "\n",
    "df_grp2_3 = df.loc[(df['session'] == 'ext3') & (df['measurement'] == MEASUREMENT)\n",
    "                 & (df['HR_responder'] == GROUP2['HR_responder']) & (df['HR_discriminator'] == GROUP2['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP2['EDA_responder']) & (df['EDA_discriminator'] == GROUP2['EDA_discriminator'])].copy()\n",
    "\n",
    "\n",
    "grp1_discrim_1 = df_grp1_1.loc[df_grp1_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_sem_1 = df_grp1_1.loc[df_grp1_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp1_discrim_2 = df_grp1_2.loc[df_grp1_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_sem_2 = df_grp1_2.loc[df_grp1_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp1_discrim_3 = df_grp1_3.loc[df_grp1_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp1_discrim_sem_3 = df_grp1_3.loc[df_grp1_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "grp2_discrim_1 = df_grp2_1.loc[df_grp2_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_sem_1 = df_grp2_1.loc[df_grp2_1['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp2_discrim_2 = df_grp2_2.loc[df_grp2_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_sem_2 = df_grp2_2.loc[df_grp2_2['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "grp2_discrim_3 = df_grp2_3.loc[df_grp2_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].mean()\n",
    "grp2_discrim_sem_3 = df_grp2_3.loc[df_grp2_3['value_type'] == 'norm_global_discrim_ratio'].iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "plt.errorbar(x = list(grp1_discrim_1.index), y = grp1_discrim_1.values, yerr = grp1_discrim_sem_1.values, color=GROUP1['color'], label='Ext1')\n",
    "plt.errorbar(x = list(grp1_discrim_2.index), y = grp1_discrim_2.values, yerr = grp1_discrim_sem_2.values, color=GROUP1['color'], label='Ext2', alpha=0.7)\n",
    "plt.errorbar(x = list(grp1_discrim_3.index), y = grp1_discrim_3.values, yerr = grp1_discrim_sem_3.values, color=GROUP1['color'], label='Ext3', alpha=0.4)\n",
    "\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - group 1', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "#fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color='g', label='discrim. ratio')\n",
    "#plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "#plt.title('Control group')\n",
    "#plt.xlabel('time in [s] from stimulus onset')\n",
    "#plt.ylabel('normalized CS responses / discrimination ratio')\n",
    "#plt.legend(loc = 'lower left')\n",
    "\n",
    "fig.add_subplot(gs[0,1], sharey=f_ax1)\n",
    "#fig.add_subplot(gs[0,2], sharey=f_ax1)\n",
    "plt.errorbar(x = list(grp2_discrim_1.index), y = grp2_discrim_1.values, yerr = grp2_discrim_sem_1.values, color=GROUP2['color'], label='Ext1')\n",
    "plt.errorbar(x = list(grp2_discrim_2.index), y = grp2_discrim_2.values, yerr = grp2_discrim_sem_2.values, color=GROUP2['color'], label='Ext2', alpha=0.7)\n",
    "plt.errorbar(x = list(grp2_discrim_3.index), y = grp2_discrim_3.values, yerr = grp2_discrim_sem_3.values, color=GROUP2['color'], label='Ext3', alpha=0.4)\n",
    "\n",
    "#plt.errorbar(x = list(ctrl_discrim.index), y = ctrl_discrim.values, yerr = ctrl_disrcim_sem.values, color=COLOR_CTRL, label='control')\n",
    "plt.hlines(0.5, xmin=-1, xmax=15, color='k', alpha = 0.4)\n",
    "plt.title('Discrimination ratios - group 2', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel('discrimination ratio', fontsize=AXES_LABEL_SIZE)\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.suptitle(MEASUREMENT + ' in session: Ext1-3', fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-profile",
   "metadata": {},
   "source": [
    "## We can also check whether there are some correlations between the classifications and baseline measurements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-genre",
   "metadata": {},
   "source": [
    "### Either using a single classification to split all subjects into two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-authority",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_individual_subjects = df.loc[(df['measurement'] == 'EDA') & (df['value_type'] == 'abs_CS-') & (df['session'] == 'preacq') & (df['stim_count'] == '1')].copy()\n",
    "\n",
    "df_individual_subjects['temp_group'] = 'remaining'\n",
    "\n",
    "df_individual_subjects.loc[(df_individual_subjects['EDA_responder'] == True), 'temp_group'] = 'group1'\n",
    "\n",
    "df_individual_subjects.loc[(df_individual_subjects['EDA_responder'] == False), 'temp_group'] = 'group2'\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8), facecolor='white')\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "dv = 'baseline_HR_Phase1'\n",
    "group = 'temp_group'\n",
    "\n",
    "df_normality = pg.normality(df_individual_subjects, dv=dv, group=group)\n",
    "df_equal_var = pg.homoscedasticity(df_individual_subjects, dv=dv, group=group)\n",
    "\n",
    "if (df_normality.iloc[0,1] > 0.05) & (df_normality.iloc[1,1] > 0.05) & (df_equal_var.iloc[0,1] > 0.05):\n",
    "    # parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.ttest(x, y)\n",
    "    p_val = df_stats['p-val']['T-test']\n",
    "    \n",
    "else:\n",
    "    # non-parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.mwu(x, y)\n",
    "    p_val = df_stats['p-val']['MWU']\n",
    "    \n",
    "sns.swarmplot(data=df_individual_subjects, x=group, y=dv, ax=f_ax1, order=['group1', 'group2'], palette=['darkorange', 'dodgerblue'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('heart rate [bpm]')\n",
    "plt.ylim(0)\n",
    "\n",
    "if p_val > 0.05:\n",
    "    title = 'Heart rates are not significantly different (p = {})'.format(str(round(p_val, 4)))  \n",
    "else:\n",
    "    title = 'Heart rates are significantly different (p = {})'.format(str(round(p_val, 4)))\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "\n",
    "f_ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "dv = 'baseline_RMSSD_Phase1'\n",
    "\n",
    "df_normality = pg.normality(df_individual_subjects, dv=dv, group=group)\n",
    "df_equal_var = pg.homoscedasticity(df_individual_subjects, dv=dv, group=group)\n",
    "\n",
    "if (df_normality.iloc[0,1] > 0.05) & (df_normality.iloc[1,1] > 0.05) & (df_equal_var.iloc[0,1] > 0.05):\n",
    "    # parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.ttest(x, y)\n",
    "    p_val = df_stats['p-val']['T-test']\n",
    "    \n",
    "else:\n",
    "    # non-parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.mwu(x, y)\n",
    "    p_val = df_stats['p-val']['MWU']\n",
    "    \n",
    "sns.swarmplot(data=df_individual_subjects, x=group, y=dv, ax=f_ax2, order=['group1', 'group2'], palette=['darkorange', 'dodgerblue'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('RMSSD')\n",
    "plt.ylim(0)\n",
    "\n",
    "if p_val > 0.05:\n",
    "    title = 'RMSSDs are not significantly different (p = {})'.format(str(round(p_val, 4)))  \n",
    "else:\n",
    "    title = 'RMSSDs are significantly different (p = {})'.format(str(round(p_val, 4)))\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-flesh",
   "metadata": {},
   "source": [
    "### Or by using the group assignments from above (might not include all subjects!): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-columbia",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_individual_subjects['temp_group'] = 'remaining'\n",
    "\n",
    "df_individual_subjects.loc[(df_individual_subjects['HR_responder'] == GROUP1['HR_responder']) & (df_individual_subjects['HR_discriminator'] == GROUP1['HR_discriminator']) & \n",
    "                           (df_individual_subjects['EDA_responder'] == GROUP1['EDA_responder']) & (df_individual_subjects['EDA_discriminator'] == GROUP1['EDA_discriminator']), \n",
    "                           'temp_group'] = 'group1'\n",
    "\n",
    "df_individual_subjects.loc[(df_individual_subjects['HR_responder'] == GROUP2['HR_responder']) & (df_individual_subjects['HR_discriminator'] == GROUP2['HR_discriminator']) & \n",
    "                           (df_individual_subjects['EDA_responder'] == GROUP2['EDA_responder']) & (df_individual_subjects['EDA_discriminator'] == GROUP2['EDA_discriminator']), \n",
    "                           'temp_group'] = 'group2'\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8), facecolor='white')\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "f_ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "dv = 'baseline_HR_Phase1'\n",
    "group = 'temp_group'\n",
    "\n",
    "df_normality = pg.normality(df_individual_subjects, dv=dv, group=group)\n",
    "df_equal_var = pg.homoscedasticity(df_individual_subjects, dv=dv, group=group)\n",
    "\n",
    "if (df_normality.iloc[0,1] > 0.05) & (df_normality.iloc[1,1] > 0.05) & (df_equal_var.iloc[0,1] > 0.05):\n",
    "    # parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.ttest(x, y)\n",
    "    p_val = df_stats['p-val']['T-test']\n",
    "    \n",
    "else:\n",
    "    # non-parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.mwu(x, y)\n",
    "    p_val = df_stats['p-val']['MWU']\n",
    "    \n",
    "sns.swarmplot(data=df_individual_subjects, x=group, y=dv, ax=f_ax1, order=['group1', 'group2'], palette=['darkorange', 'dodgerblue'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('heart rate [bpm]')\n",
    "plt.ylim(0)\n",
    "\n",
    "if p_val > 0.05:\n",
    "    title = 'Heart rates are not significantly different (p = {})'.format(str(round(p_val, 4)))  \n",
    "else:\n",
    "    title = 'Heart rates are significantly different (p = {})'.format(str(round(p_val, 4)))\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "\n",
    "f_ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "dv = 'baseline_RMSSD_Phase1'\n",
    "\n",
    "df_normality = pg.normality(df_individual_subjects, dv=dv, group=group)\n",
    "df_equal_var = pg.homoscedasticity(df_individual_subjects, dv=dv, group=group)\n",
    "\n",
    "if (df_normality.iloc[0,1] > 0.05) & (df_normality.iloc[1,1] > 0.05) & (df_equal_var.iloc[0,1] > 0.05):\n",
    "    # parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.ttest(x, y)\n",
    "    p_val = df_stats['p-val']['T-test']\n",
    "    \n",
    "else:\n",
    "    # non-parametric test\n",
    "    x = df_individual_subjects.loc[df_individual_subjects[group] == 'group1', dv].values\n",
    "    y = df_individual_subjects.loc[df_individual_subjects[group] == 'group2', dv].values\n",
    "    df_stats = pg.mwu(x, y)\n",
    "    p_val = df_stats['p-val']['MWU']\n",
    "    \n",
    "sns.swarmplot(data=df_individual_subjects, x=group, y=dv, ax=f_ax2, order=['group1', 'group2'], palette=['darkorange', 'dodgerblue'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('RMSSD')\n",
    "plt.ylim(0)\n",
    "\n",
    "if p_val > 0.05:\n",
    "    title = 'RMSSDs are not significantly different (p = {})'.format(str(round(p_val, 4)))  \n",
    "else:\n",
    "    title = 'RMSSDs are significantly different (p = {})'.format(str(round(p_val, 4)))\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-increase",
   "metadata": {},
   "source": [
    "## To see all \"session mean\" responses individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_TYPE = 'norm_global_CS+'\n",
    "STIM_COUNT = 'session_mean'\n",
    "MEASUREMENT = 'HR'\n",
    "SESSION = 'acq2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-material",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Depending on whether df is created by reading a .csv file or from preprocessing, the timepoints seem to be stored differently (as int or as str). To catch this error:\n",
    "if '-1' in df.columns:\n",
    "    column_a, column_b = '-1', '15'\n",
    "elif -1 in df.columns:\n",
    "    column_a, column_b = -1, 15\n",
    "\n",
    "# To make this plot highly flexible, e.g. if additional columns are added with regard to responder classifications and so on, the column indices are not hard coded:\n",
    "idx_start = list(df.columns).index(column_a)\n",
    "idx_stop = list(df.columns).index(column_b)\n",
    "\n",
    "\n",
    "df_grp1 = df.loc[(df['session'] == SESSION) & (df['value_type'] == VALUE_TYPE) & (df['measurement'] == MEASUREMENT) & (df['stim_count'] == STIM_COUNT) \n",
    "                 & (df['HR_responder'] == GROUP1['HR_responder']) & (df['HR_discriminator'] == GROUP1['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP1['EDA_responder']) & (df['EDA_discriminator'] == GROUP1['EDA_discriminator'])].copy()\n",
    "\n",
    "\n",
    "df_grp2 = df.loc[(df['session'] == SESSION) & (df['value_type'] == VALUE_TYPE) & (df['measurement'] == MEASUREMENT) & (df['stim_count'] == STIM_COUNT) \n",
    "                 & (df['HR_responder'] == GROUP2['HR_responder']) & (df['HR_discriminator'] == GROUP2['HR_discriminator'])\n",
    "                 & (df['EDA_responder'] == GROUP2['EDA_responder']) & (df['EDA_discriminator'] == GROUP2['EDA_discriminator'])].copy()\n",
    "\n",
    "mean_grp1 = df_grp1.iloc[:, idx_start:idx_stop].mean()\n",
    "sem_grp1 = df_grp1.iloc[:, idx_start:idx_stop].sem()\n",
    "mean_grp2 = df_grp2.iloc[:, idx_start:idx_stop].mean()\n",
    "sem_grp2 = df_grp2.iloc[:, idx_start:idx_stop].sem()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "df_grp1.iloc[:, idx_start:idx_stop].transpose().plot(legend=False, alpha=.2, color=GROUP1['color'], ax=ax1)\n",
    "plt.errorbar(x = list(mean_grp1.index), y = mean_grp1.values, yerr = sem_grp1.values, color=GROUP1['color'])\n",
    "plt.title('Group 1', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel(VALUE_TYPE, fontsize=AXES_LABEL_SIZE)\n",
    "#plt.ylim(0.25, 0.4)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1], sharey=ax1)\n",
    "df_grp2.iloc[:, idx_start:idx_stop].transpose().plot(legend=False, alpha=.2, color=GROUP2['color'], ax=ax2)\n",
    "plt.errorbar(x = list(mean_grp2.index), y = mean_grp2.values, yerr = sem_grp2.values, color=GROUP2['color'])\n",
    "plt.title('Group 2', fontsize=SUBTITLE_SIZE)\n",
    "plt.xlabel('time in [s] from stimulus onset', fontsize=AXES_LABEL_SIZE)\n",
    "plt.ylabel(VALUE_TYPE, fontsize=AXES_LABEL_SIZE)\n",
    "\n",
    "plt.suptitle(VALUE_TYPE + ' for ' + MEASUREMENT + ' in session: ' + SESSION, fontsize = TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-smell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
