{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/ds/DCL/Defensive_states/session_data_ceiling/OF-EPM-PreExp-CD1-CD2-Ext-ExtCont-ExtHC_Export_26-May-2021_18-50-37.mat'\n",
    "data = loadmat(filepath)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .mat file that contains the data from all sessions\n",
    "filepath = '/home/ds/DCL/Defensive_states/session_data_ceiling/OF-EPM-PreExp-CD1-CD2-Ext-ExtCont-ExtHC_Export_26-May-2021_18-50-37.mat'\n",
    "data = loadmat(filepath)\n",
    "\n",
    "# Extract all column names. Each column name contains information about the mice ('Animal_ID')\n",
    "# and about the date and the type of recording session, e.g.: '175_F4-31_190823_OF'\n",
    "l_all_column_names = [s[0] for s in list(data['Headers'][0])]\n",
    "\n",
    "# The data was recorded from the following sessions:\n",
    "l_sessions = ['OF', 'EPM', 'PreExp', 'CD1', 'CD2', 'Ext', 'ExtCont', 'ExtHC']\n",
    "\n",
    "\n",
    "all_dfs_all_sessions = []\n",
    "\n",
    "for session in l_sessions:\n",
    "    l_session_column_names = []\n",
    "    l_session_column_ids = []\n",
    "    all_dfs_of_one_session = []\n",
    "    \n",
    "    # Define the name of all columns that belong to the respective session\n",
    "    l_session_column_names = [column_name for column_name in l_all_column_names if column_name.endswith(session)]\n",
    "    l_session_column_ids = [l_all_column_names.index(column_name) for column_name in l_session_column_names]\n",
    "    \n",
    "    # Get a list of all animals that were recorded in this session and a list with the corresponding dates:\n",
    "    #l_session_animals = [column_name[:column_name.find('_', column_name.find('_')+1)] for column_name in l_session_column_names]\n",
    "    #l_session_dates = [column_name[column_name.find('_', column_name.find('_')+1)+1:column_name.rfind('_')] for column_name in l_session_column_names]\n",
    "    \n",
    "    # Extract the data for each animal individually\n",
    "    for column_name in l_session_column_names:\n",
    "        column_id = l_all_column_names.index(column_name)\n",
    "        \n",
    "        \n",
    "        # Extract remaining metadata: animal_id and date\n",
    "        animal_id = column_name[:column_name.find('_', column_name.find('_')+1)]\n",
    "        date = column_name[column_name.find('_', column_name.find('_')+1)+1:column_name.rfind('_')]\n",
    "        \n",
    "        # Extract measurements, behaviors and events\n",
    "        dict_animal = {# Timestamps:\n",
    "                       'Times': data['Times'][:, column_id].tolist(),\n",
    "                       \n",
    "                       # Heart rate related measures:\n",
    "                       'HeartRate': data['HeartRate'][:, column_id].tolist(),\n",
    "                       # Low frequency band heart rate:\n",
    "                       #'HR_Low_Amp': data['HeartRateWv']['Low'][0][0]['Amp'][0][0][:, column_id].tolist(),\n",
    "                       'HR_Low_Signal': data['HR_Low_Signal'][:, column_id].tolist(),\n",
    "                       #'HR_Low_Delta': data['HeartRateWv']['Low'][0][0]['Delta'][0][0][:, column_id].tolist(),\n",
    "                       # Medium frequency band heart rate:\n",
    "                       'HR_Med_Amp': data['HR_Medium_Amp'][:, column_id].tolist(),\n",
    "                       #'HR_Med_Signal': data['HeartRateWv']['Medium'][0][0]['Signal'][0][0][:, column_id].tolist(),\n",
    "                       'HR_Med_Delta': data['HR_Medium_Delta'][:, column_id].tolist(),\n",
    "                       # High frequency band heart rate:\n",
    "                       'HR_High_Amp': data['HR_High_Amp'][:, column_id].tolist(),\n",
    "                       #'HR_High_Signal': data['HeartRateWv']['High'][0][0]['Signal'][0][0][:, column_id].tolist(),\n",
    "                       #'HR_High_Delta': data['HeartRateWv']['High'][0][0]['Delta'][0][0][:, column_id].tolist(),\n",
    "\n",
    "                       'Ceiling': data['Ceiling'][:, column_id].tolist(),\n",
    "                       'DistanceToCeiling': data['DistanceToCeiling'][:, column_id].tolist(),\n",
    "                       \n",
    "            \n",
    "                       # Motion-related measures:\n",
    "                       'Motion': data['Motion'][:, column_id].tolist(),\n",
    "                       # Low frequency band motion:\n",
    "                       #'M_Low_Amp': data['MotionWv']['Low'][0][0]['Amp'][0][0][:, column_id].tolist(),\n",
    "                       #'M_Low_Signal': data['MotionWv']['Low'][0][0]['Signal'][0][0][:, column_id].tolist(),         \n",
    "                       #'M_Low_Delta': data['MotionWv']['Low'][0][0]['Delta'][0][0][:, column_id].tolist(),\n",
    "                       # High frequency band motion:\n",
    "                       #'M_High_Amp': data['MotionWv']['High'][0][0]['Amp'][0][0][:, column_id].tolist(),\n",
    "                       #'M_High_Signal': data['MotionWv']['High'][0][0]['Signal'][0][0][:, column_id].tolist(),\n",
    "                       #'M_High_Delta': data['MotionWv']['High'][0][0]['Delta'][0][0][:, column_id].tolist(),\n",
    "                       # In addition - AreaExplored and Speed:\n",
    "                       'AreaExplored': data['AreaExplored'][:, column_id].tolist(),\n",
    "                       'Speed': data['Speed'][:, column_id].tolist(),\n",
    "                       \n",
    "                       # Temperature all four tail segments:\n",
    "                       'Temperature': data['Temperature'][:, column_id].tolist(),\n",
    "                       #'Temperature_s2': data['Temperature']['Second'][0][0][:, column_id].tolist(),\n",
    "                       #'Temperature_s3': data['Temperature']['Third'][0][0][:, column_id].tolist(),\n",
    "                       #'Temperature_s4': data['Temperature']['Fourth'][0][0][:, column_id].tolist(),\n",
    "                       \n",
    "                       # FastTemperature all four tail segments:\n",
    "                       #'FastTemperature_s1': data['FastTemperature']['First'][0][0][:, column_id].tolist(),\n",
    "                       #'FastTemperature_s2': data['FastTemperature']['Second'][0][0][:, column_id].tolist(),\n",
    "                       #'FastTemperature_s3': data['FastTemperature']['Third'][0][0][:, column_id].tolist(),\n",
    "                       #'FastTemperature_s4': data['FastTemperature']['Fourth'][0][0][:, column_id].tolist(),\n",
    "\n",
    "                       # Behaviors\n",
    "                       'Immobility': data['Behaviours']['Immobility'][0][0][:, column_id].tolist(),\n",
    "                       'Rearing': data['Behaviours']['Rearing'][0][0][:, column_id].tolist(),\n",
    "                       'StretchAttend': data['Behaviours']['StretchAttend'][0][0][:, column_id].tolist(),\n",
    "                       'TailRattling': data['Behaviours']['TailRattling'][0][0][:, column_id].tolist(),\n",
    "                       'Grooming': data['Behaviours']['Grooming'][0][0][:, column_id].tolist(),\n",
    "                       'Flight': data['Behaviours']['Flight'][0][0][:, column_id].tolist(),\n",
    "                       'HeadDips': data['Behaviours']['HeadDips'][0][0][:, column_id].tolist(),\n",
    "                       'Remaining': data['Behaviours']['Remaining'][0][0][:, column_id].tolist(),\n",
    "                       #'Struggle': data['Behaviours']['Struggle'][0][0][:, column_id].tolist(),  \n",
    "                       'AreaBound': data['Behaviours']['AreaBound'][0][0][:, column_id].tolist(),\n",
    "\n",
    "                       # Events:\n",
    "                       'PureTone': data['Events']['PureTone'][0][0][:, column_id].tolist(), \n",
    "                       'WhiteNoise': data['Events']['WhiteNoise'][0][0][:, column_id].tolist(), \n",
    "                       'Shock': data['Events']['Shock'][0][0][:, column_id].tolist(),\n",
    "\n",
    "                       # Exclusion ranges:\n",
    "                       'ExclusionRanges': data['ExclusionRanges'][:, column_id].tolist()\n",
    "            \n",
    "                       }\n",
    "\n",
    "        # Create DataFrame that contains all measurements from one animal of this session & add metadata    \n",
    "        df_temp = pd.DataFrame(data = dict_animal)\n",
    "        df_temp.reset_index(inplace = True)\n",
    "        df_temp.rename(columns = {'index':'Bin'}, inplace = True)\n",
    "        df_temp.insert(0, 'Session', session)\n",
    "        df_temp.insert(1, 'Animal_ID', animal_id)\n",
    "        df_temp.insert(2, 'Date', date)\n",
    "        \n",
    "        # Append to list of dfs from the other mice of this session that will be concatenated \n",
    "        all_dfs_of_one_session.append(df_temp)\n",
    "        \n",
    "    # Concatenate the dfs of all animals of this session and append it to the list of dfs of all sessions    \n",
    "    df_one_session = pd.concat(all_dfs_of_one_session, ignore_index = True)\n",
    "    all_dfs_all_sessions.append(df_one_session)\n",
    "    \n",
    "# Concatenate all session dfs to a single df that contains all data:\n",
    "df = pd.concat(all_dfs_all_sessions, ignore_index = True)\n",
    "#df = df.dropna()\n",
    "\n",
    "df['Exclude'] = False\n",
    "\n",
    "# Exclude unphysiological temperature values right away:\n",
    "#df.loc[(df['Temperature_s1'] < 10) | (df['Temperature_s3'] < 10) | \n",
    "#       (df['Temperature_s1'] > 40) | (df['Temperature_s3'] > 40), 'Exclude'] = True\n",
    "\n",
    "# Exclude time bins that are marked as to be excluded in ExclusionRanges (as nan):\n",
    "#df.loc[df['Struggle'] == 1, 'Exclude'] = True\n",
    "df.loc[df['ExclusionRanges'].isnull(), 'Exclude'] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Some data has to be excluded from the analysis. Define the exclusion criteria:\n",
    "#exclusion_criteria = [('Shock', 1), ('Outlier', True)]\n",
    "\n",
    "#for criterion in exclusion_criteria:\n",
    "#    column, value = criterion[0], criterion[1]\n",
    "#    df.loc[df[column] == value, 'Exclude'] = True\n",
    "\n",
    "# In addition, data exploration revealed some issues with the data. The following lines mark those data as 'to be excluded'\n",
    "# linear decrease of HR at end of ExtHC after 2121.0 seconds\n",
    "#df.loc[(df['Animal_ID'] == '175_F4-39') & (df['Session'] == 'ExtHC') & (df['Times'] > 2121.0), 'Exclude'] = True\n",
    "# Strongly different Signal values (HR_Low and HR_Med) compared to all other mice:\n",
    "df.loc[(df['Animal_ID'] == '175_F4-39') & (df['Session'] == 'ExtHC'), 'Exclude'] = True\n",
    "# linear increase of HR at end of CD1 after 887.0 seconds\n",
    "df.loc[(df['Animal_ID'] == '175_F4-25') & (df['Session'] == 'CD1') & (df['Times'] > 887.0), 'Exclude'] = True \n",
    "# Linear increase of Temperature at start of CD2  during first 187.0 seconds\n",
    "df.loc[(df['Animal_ID'] == '175_F6-8') & (df['Session'] == 'CD2') & (df['Times'] < 187.0), 'Exclude'] = True \n",
    "\n",
    "\n",
    "# Behaviors are indicated in a single column to make plotting easier\n",
    "df['behaviors'] = 'No score'\n",
    "\n",
    "for behavior in ['Immobility', 'Rearing', 'StretchAttend', 'TailRattling', 'Grooming', 'Flight', 'Remaining', 'HeadDips', 'AreaBound']:\n",
    "    df.loc[df[behavior] == 1, 'behaviors'] = behavior\n",
    "\n",
    "df_temp = df[['Immobility', 'Rearing', 'StretchAttend', 'TailRattling', 'Grooming', 'Flight', 'Remaining', 'HeadDips', 'AreaBound']].copy()\n",
    "df_temp['sum'] = df_temp.sum(axis=1)\n",
    "l_idx_mutliple_behaviors = list(df_temp.loc[df_temp['sum'] > 1].index)\n",
    "df.loc[l_idx_mutliple_behaviors,'behaviors'] = 'multiple'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add information about bout duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add information about bout duration. These loops will take some time, so let´s print some information on the progress:\n",
    "print('Done with most of the preprocessing - only bout durations are missing!\\n')\n",
    "print('...starting with bout duration processing now...')\n",
    "\n",
    "# For this we need two additional functions: get_ & write_duration\n",
    "def get_duration(behavior_to_match, idx, idx_max):\n",
    "    duration = 0\n",
    "    behavior = df.loc[idx, 'behaviors']\n",
    "    while (behavior == behavior_to_match) & (idx <= idx_max):\n",
    "        duration = duration + 1\n",
    "        idx = idx + 1\n",
    "        if idx <= idx_max:\n",
    "            behavior = df.loc[idx, 'behaviors']\n",
    "    return duration, idx\n",
    "\n",
    "def write_duration(idx_start, idx_last, duration):\n",
    "    bin_count = 1\n",
    "    for idx in range(idx_start, idx_last):\n",
    "        df.loc[idx, 'Bout_bin'] = bin_count\n",
    "        df.loc[idx, 'Bout_duration'] = duration\n",
    "        bin_count = bin_count + 1\n",
    "\n",
    "# Bins that are not classified as belonging to a relevant behavior (e.g. being classified as 'Remaining', 'No score', or 'multiple') will have the following value\n",
    "# We might think about using np.NaN instead of 0´s instead?! If both UMAP and HDBSCAN can handle this?\n",
    "df['Bout_bin'] = 0\n",
    "df['Bout_duration'] = 0\n",
    "\n",
    "for Animal_ID in list(df['Animal_ID'].unique()):\n",
    "    for Session in list(df.loc[df['Animal_ID'] == Animal_ID, 'Session'].unique()):\n",
    "        print('Processing bout data of: ' + Animal_ID + ' during ' + Session)\n",
    "        df_bouts = df.loc[(df['Animal_ID'] == Animal_ID) & (df['Session'] == Session)].copy()\n",
    "        \n",
    "        idx_start = df_bouts.index[0]\n",
    "        idx_max = df_bouts.index[0] + df_bouts.shape[0] -1\n",
    "\n",
    "        idx = idx_start\n",
    "\n",
    "        while (idx >= idx_start) & (idx <= idx_max):\n",
    "            behavior_to_match = df_bouts.loc[idx, 'behaviors']\n",
    "            if behavior_to_match in ['Immobility', 'Rearing', 'StretchAttend', 'Grooming', 'Flight', 'TailRattling', 'HeadDips']: #, 'OpenRearing'\n",
    "                duration, idx_last = get_duration(behavior_to_match, idx, idx_max)\n",
    "                write_duration(idx, idx_last, duration)\n",
    "                idx = idx_last\n",
    "            else:\n",
    "                idx = idx + 1\n",
    "    \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and remove mice that don´t have recorded data for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sessions_per_mouse = {}\n",
    "\n",
    "for mouse in df['Animal_ID'].unique():\n",
    "    dict_sessions_per_mouse[mouse] = list(df.loc[df['Animal_ID'] == mouse, 'Session'].unique())\n",
    "    \n",
    "l_mice_to_remove = []\n",
    "l_mice_to_keep = []\n",
    "\n",
    "\n",
    "sessions_to_check = ['OF', 'EPM', 'CD1', 'CD2']\n",
    "\n",
    "\n",
    "for mouse in df['Animal_ID'].unique():\n",
    "    l_session_check = []\n",
    "    \n",
    "    for session in sessions_to_check:\n",
    "        l_session_check.append(session in dict_sessions_per_mouse[mouse])\n",
    "\n",
    "    if all(l_session_check):\n",
    "        l_mice_to_keep.append(mouse)\n",
    "\n",
    "    else:\n",
    "        l_mice_to_remove.append(mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Animal_ID'].isin(l_mice_to_keep)]\n",
    "df = df.loc[df['Session'].isin(sessions_to_check)]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_measures_to_scale =  ['HeartRate',\n",
    "                        'HR_Low_Signal', #'HR_Low_Delta', 'HR_Low_Amp',\n",
    "                        'HR_Med_Delta', 'HR_Med_Amp', #'HR_Med_Signal', \n",
    "                        'HR_High_Amp', #'HR_High_Signal', 'HR_High_Delta', \n",
    "                        'Ceiling', 'DistanceToCeiling',\n",
    "                        'Motion',\n",
    "                        #'M_Low_Signal', 'M_Low_Delta', 'M_Low_Amp',\n",
    "                        #'M_High_Signal', 'M_High_Delta', 'M_High_Amp',\n",
    "                        'AreaExplored', 'Speed',\n",
    "                        'Temperature']\n",
    "                        #'Temperature_s2', , 'Temperature_s4',\n",
    "                        #'FastTemperature_s1', 'FastTemperature_s2', 'FastTemperature_s3','FastTemperature_s4']\n",
    "\n",
    "\n",
    "min_maxes = {}\n",
    "\n",
    "df_check_nans = df.dropna().copy()\n",
    "for measure in l_measures_to_scale:\n",
    "    \n",
    "    # Get actual values of min and max\n",
    "    min_ = np.percentile(df_check_nans.loc[df['Exclude'] == False, measure].values, 0.05)\n",
    "    max_ = np.percentile(df_check_nans.loc[df['Exclude'] == False, measure].values, 99.95)\n",
    "    \n",
    "    # Pass them into the dictionary\n",
    "    min_maxes[measure] = [min_, max_]\n",
    "\n",
    "print('These are the calculated Min-Maxes for each measure:')\n",
    "min_maxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in min_maxes.keys():\n",
    "    min_, max_ = min_maxes[measure][0], min_maxes[measure][1]\n",
    "    df.loc[(df[measure] >= min_) & (df[measure] <= max_), 'norm_' + measure] = (df[measure] - min_) / (max_ - min_)\n",
    "    df.loc[df[measure] < min_, 'Exclude'] = True\n",
    "    df.loc[df[measure] > max_, 'Exclude'] = True             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Animal_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Coefficient of variation with different sliding window sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoVs_from_sliding_windows(array, half_window_size):\n",
    "    l_CoVs = []\n",
    "    for Bin in range(len(array)):\n",
    "        if Bin < half_window_size:\n",
    "            # Handle values at the beginning differently?\n",
    "            start_bin = 0\n",
    "            end_bin = Bin + half_window_size\n",
    "            l_CoVs.append(stats.variation(array[:end_bin], nan_policy='omit'))\n",
    "\n",
    "        elif Bin > (len(array)-half_window_size-1):\n",
    "            # Handle values at the end differently?\n",
    "            start_bin = Bin - half_window_size\n",
    "            end_bin = len(array) - 1\n",
    "            l_CoVs.append(stats.variation(array[start_bin:], nan_policy='omit'))\n",
    "\n",
    "        else:\n",
    "            start_bin = Bin - half_window_size\n",
    "            end_bin = Bin + half_window_size\n",
    "            l_CoVs.append(stats.variation(array[start_bin:end_bin], nan_policy='omit'))\n",
    "        \n",
    "    CoVs = np.array(l_CoVs)\n",
    "    return CoVs\n",
    "\n",
    "df['HR_CoV_10s'] = np.NaN\n",
    "\n",
    "for mouse in df['Animal_ID'].unique():\n",
    "    for session in df.loc[df['Animal_ID'] == mouse, 'Session'].unique():\n",
    "        heart_rate_array = df.loc[(df['Animal_ID'] == mouse) & (df['Session'] == session), 'HeartRate'].values\n",
    "        df.loc[(df['Animal_ID'] == mouse) & (df['Session'] == session), 'HR_CoV_10s'] = CoVs_from_sliding_windows(heart_rate_array, 20)\n",
    "        \n",
    "# Scale it globally:\n",
    "min_, max_ = df.loc[df['Exclude'] == False, 'HR_CoV_10s'].min(), df.loc[df['Exclude'] == False, 'HR_CoV_10s'].max()\n",
    "df['norm_HR_CoV_10s'] = (df['HR_CoV_10s'] - min_) / (max_ - min_)\n",
    "\n",
    "\n",
    "df['HR_CoV_5s'] = np.NaN\n",
    "\n",
    "for mouse in df['Animal_ID'].unique():\n",
    "    for session in df.loc[df['Animal_ID'] == mouse, 'Session'].unique():\n",
    "        heart_rate_array = df.loc[(df['Animal_ID'] == mouse) & (df['Session'] == session), 'HeartRate'].values\n",
    "        df.loc[(df['Animal_ID'] == mouse) & (df['Session'] == session), 'HR_CoV_5s'] = CoVs_from_sliding_windows(heart_rate_array, 10)\n",
    "        \n",
    "# Scale it globally:\n",
    "min_, max_ = df.loc[df['Exclude'] == False, 'HR_CoV_5s'].min(), df.loc[df['Exclude'] == False, 'HR_CoV_5s'].max()\n",
    "df['norm_HR_CoV_5s'] = (df['HR_CoV_5s'] - min_) / (max_ - min_)\n",
    "\n",
    "\n",
    "df['HR_CoV_2s'] = np.NaN\n",
    "\n",
    "for mouse in df['Animal_ID'].unique():\n",
    "    for session in df.loc[df['Animal_ID'] == mouse, 'Session'].unique():\n",
    "        heart_rate_array = df.loc[(df['Animal_ID'] == mouse) & (df['Session'] == session), 'HeartRate'].values\n",
    "        df.loc[(df['Animal_ID'] == mouse) & (df['Session'] == session), 'HR_CoV_2s'] = CoVs_from_sliding_windows(heart_rate_array, 8)\n",
    "        \n",
    "# Scale it globally:\n",
    "min_, max_ = df.loc[df['Exclude'] == False, 'HR_CoV_2s'].min(), df.loc[df['Exclude'] == False, 'HR_CoV_2s'].max()\n",
    "df['norm_HR_CoV_2s'] = (df['HR_CoV_2s'] - min_) / (max_ - min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square-root transformation of AreaExplored after scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df['norm_Motion_sqrt'] = np.sqrt(df['norm_Motion'])\n",
    "\n",
    "# Not done for Speed and AreaExplored to avoid loosing the physical meaning of this dimension:\n",
    "df['norm_AreaExplored_sqrt'] = np.sqrt(df['norm_AreaExplored'])\n",
    "df['norm_DistanceToCeiling_sqrt'] = np.sqrt(1 - df['norm_DistanceToCeiling'])\n",
    "# df['norm_Speed_sqrt'] = np.sqrt(df['norm_Speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep all NaNs in order to visualize ranges of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_nans = df.copy()\n",
    "\n",
    "# Now df can be cleared of NaNs:\n",
    "df = df.dropna()\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the processed and scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('States_ceiling_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), 'norm_HeartRate'], color='blue', alpha=0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect distributions with calculated min - maxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASURE = 'norm_DistanceToCeiling'\n",
    "\n",
    "BIN_COUNT = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEASURE.startswith('norm_'):\n",
    "    MIN, MAX = 0, 1\n",
    "else:\n",
    "    MIN, MAX = min_maxes[MEASURE][0], min_maxes[MEASURE][1]\n",
    "\n",
    "\n",
    "BINWIDTH = (df.loc[df['Exclude'] == False, MEASURE].max() - df.loc[df['Exclude'] == False, MEASURE].min()) / 1000\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10), facecolor='white')\n",
    "gs = fig.add_gridspec(2,2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "sns.histplot(data=df.loc[df['Exclude'] == False], x=MEASURE, bins=BIN_COUNT, ax=ax1)\n",
    "plt.title('All data')\n",
    "plt.axvline(x=MIN, linestyle='dashed', color='r')\n",
    "plt.axvline(x=MAX, linestyle='dashed', color='r')\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "sns.histplot(data=df.loc[df['Exclude'] == False], x=MEASURE, bins=BIN_COUNT, ax=ax2) #, hue='Animal_ID', palette='colorblind', alpha=0.3, legend=False\n",
    "plt.ylim(0,75) \n",
    "plt.title('All data - focus on less frequent values')\n",
    "plt.axvline(x=MIN, linestyle='dashed', color='r')\n",
    "plt.axvline(x=MAX, linestyle='dashed', color='r')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1,0])    \n",
    "sns.histplot(data=df.loc[df['Exclude'] == False], x=MEASURE, bins=BIN_COUNT, ax=ax3)\n",
    "plt.ylim(0, 20)\n",
    "plt.xlim(MIN - 25*BINWIDTH, MIN + 25*BINWIDTH)\n",
    "plt.title('Focus on lower range')\n",
    "plt.axvline(x=MIN, linestyle='dashed', color='r')\n",
    "\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1,1])    \n",
    "sns.histplot(data=df.loc[df['Exclude'] == False], x=MEASURE, bins=BIN_COUNT, ax=ax4)\n",
    "plt.ylim(0, 20)\n",
    "plt.xlim(MAX - 25*BINWIDTH, MAX + 25*BINWIDTH)\n",
    "plt.title('Focus on upper range')\n",
    "plt.axvline(x=MAX, linestyle='dashed', color='r')\n",
    "\n",
    "filename = 'Global_limits_for_' + MEASURE + '.pdf'\n",
    "#plt.savefig(filename)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASURE = 'norm_HR_Med_Amp'\n",
    "\n",
    "if MEASURE.startswith('norm_'):\n",
    "    MIN, MAX = 0, 1\n",
    "else:\n",
    "    MIN, MAX = min_maxes[MEASURE][0], min_maxes[MEASURE][1]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8), facecolor='white')\n",
    "gs = fig.add_gridspec(1,1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "sns.histplot(data=df.loc[df['Exclude'] == False], x=MEASURE, bins=BIN_COUNT, ax=ax1, hue='Animal_ID')\n",
    "plt.title('All data')\n",
    "plt.axvline(x=MIN, linestyle='dashed', color='r')\n",
    "plt.axvline(x=MAX, linestyle='dashed', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_measures = ['norm_HeartRate', 'norm_HR_Low_Signal', 'norm_HR_Med_Delta',\n",
    "'norm_HR_Med_Amp', 'norm_HR_High_Amp', 'norm_Ceiling',\n",
    "'norm_DistanceToCeiling', 'norm_Motion', 'norm_AreaExplored',\n",
    "'norm_Speed', 'norm_Temperature', 'norm_HR_CoV_10s',\n",
    "'norm_HR_CoV_5s', 'norm_HR_CoV_2s']\n",
    "\n",
    "\n",
    "dict_distributions = {'step': [],\n",
    "                      'number_of_mice': [],\n",
    "                      'dimension': []}\n",
    "\n",
    "for dimension in l_measures:\n",
    "    l_no_of_mice, l_steps, l_dimensions = [], [], []\n",
    "    for step in np.linspace(0,1,21):\n",
    "        l_steps.append(step.round(2))\n",
    "        l_no_of_mice.append(df.loc[df[dimension] > step, 'Animal_ID'].unique().shape[0])\n",
    "        l_dimensions.append(dimension)\n",
    "    dict_distributions['step'] = dict_distributions['step'] + l_steps\n",
    "    dict_distributions['number_of_mice'] = dict_distributions['number_of_mice'] + l_no_of_mice    \n",
    "    dict_distributions['dimension'] = dict_distributions['dimension'] + l_dimensions    \n",
    "        \n",
    "df_distributions = pd.DataFrame(data=dict_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "\n",
    "sns.pointplot(data=df_distributions, x='step', y='number_of_mice', hue='dimension', palette='Spectral', dodge=True)\n",
    "plt.xlabel('threshold value', fontsize=15)\n",
    "plt.ylabel('Number of mice with data exceeding threshold value', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_new_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distributions.loc[(df_distributions['number_of_mice'] >= 9) & (df_distributions['step'] == 0.65), 'dimension'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_new_default == l_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc[df['norm_HR_Low_Signal'] > 0.8, 'Animal_ID'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot traces of all dimensions for each mouse and each recorded session\n",
    "\n",
    "Excluded areas are left blank in the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan_check = df_with_nans.copy()\n",
    "df_nan_check['NaN_count'] = df_nan_check.iloc[:, 5:].isnull().sum(axis=1)\n",
    "exclude_column_id = list(df_nan_check.columns).index('Exclude')\n",
    "df_nan_check.loc[df_nan_check['NaN_count'] > 0, df_nan_check.columns[5:exclude_column_id]] = np.NaN \n",
    "df_nan_check.loc[df_nan_check['NaN_count'] > 0, df_nan_check.columns[exclude_column_id+1:-1]] = np.NaN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperatures of tail segments 1 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(60,100), facecolor='white')\n",
    "gs = fig.add_gridspec(38, 7)\n",
    "\n",
    "\n",
    "l_measures = ['norm_Temperature_s1', 'norm_Temperature_s3']\n",
    "legend_title = 'Temperatures:'\n",
    "l_labels = ['segment 1', 'segment 3']\n",
    "\n",
    "\n",
    "row = 0\n",
    "for mouse in df_nan_check['Animal_ID'].unique():\n",
    "    for column in range(7):\n",
    "        session = ['OF', 'EPM', 'PreExp', 'CD1', 'CD2', 'Ext', 'ExtCont'][column]\n",
    "        if session == 'Ext':\n",
    "            if df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[0]].shape[0] == 0:\n",
    "                session = 'ExtHC'\n",
    "        fig.add_subplot(gs[row, column])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[0]], color='blue', alpha=0.75, label=l_labels[0])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[1]], color='darkorange', alpha=0.75, label=l_labels[1])\n",
    "        #plt.plot(df.loc[(df['Exclude'] == False) & (df['Animal_ID'] == mouse) & (df['Session'] == session), l_measures[2]], color='cyan', alpha=0.75, label=l_labels[2])\n",
    "        #plt.plot(df.loc[(df['Exclude'] == False) & (df['Animal_ID'] == mouse) & (df['Session'] == session), l_measures[3]], color='k', alpha=0.5, label=l_labels[3])\n",
    "        plt.ylim(0,1)\n",
    "        if column == 0:\n",
    "            plt.ylabel(mouse)\n",
    "        if row == 0:\n",
    "            if session == 'Ext':\n",
    "                plt.title('Ext / ExtHC')\n",
    "            elif session == 'ExtHC':\n",
    "                plt.title('Ext / ExtHC')\n",
    "            else:\n",
    "                plt.title(session)\n",
    "            \n",
    "        if column == 6:\n",
    "            plt.legend(title= legend_title, loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "        else:\n",
    "            plt.legend('', frameon=False)\n",
    "    row = row + 1\n",
    "\n",
    "plt.savefig('Temperatures_all_sessions_v10_NaNs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion related measures: Speed, AreaExplored (sqrt. transformed), and Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(60,100), facecolor='white')\n",
    "gs = fig.add_gridspec(38, 7)\n",
    "\n",
    "\n",
    "l_measures = ['norm_Speed', 'norm_AreaExplored_sqrt', 'norm_Motion']\n",
    "legend_title = 'Motion measures:'\n",
    "l_labels = ['Speed', 'AreaExplored sqrt.', 'Motion']\n",
    "\n",
    "\n",
    "row = 0\n",
    "for mouse in df_nan_check['Animal_ID'].unique():\n",
    "    for column in range(7):\n",
    "        session = ['OF', 'EPM', 'PreExp', 'CD1', 'CD2', 'Ext', 'ExtCont'][column]\n",
    "        if session == 'Ext':\n",
    "            if df.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[0]].shape[0] == 0:\n",
    "                session = 'ExtHC'\n",
    "        fig.add_subplot(gs[row, column])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[0]], color='blue', alpha=0.75, label=l_labels[0])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[1]], color='darkorange', alpha=0.75, label=l_labels[1])\n",
    "        #plt.plot(df.loc[(df['Exclude'] == False) & (df['Animal_ID'] == mouse) & (df['Session'] == session), l_measures[2]], color='cyan', alpha=0.75, label=l_labels[2])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[2]], color='k', alpha=0.5, label=l_labels[2])\n",
    "        plt.ylim(0,1)\n",
    "        if column == 0:\n",
    "            plt.ylabel(mouse)\n",
    "        if row == 0:\n",
    "            if session == 'Ext':\n",
    "                plt.title('Ext / ExtHC')\n",
    "            elif session == 'ExtHC':\n",
    "                plt.title('Ext / ExtHC')\n",
    "            else:\n",
    "                plt.title(session)\n",
    "            \n",
    "        if column == 6:\n",
    "            plt.legend(title= legend_title, loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "        else:\n",
    "            plt.legend('', frameon=False)\n",
    "    row = row + 1\n",
    "\n",
    "plt.savefig('Speed_Area_Motion_all_sessions_v10_NaNs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR related measures: HeartRate, Amplitude of the high frequency band (globally scaled), and the CoV with a sliding window of 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(60, 100), facecolor='white')\n",
    "gs = fig.add_gridspec(38, 7)\n",
    "\n",
    "\n",
    "l_measures = ['norm_HR_High_Amp', 'norm_HR_CoV_10s', 'norm_HeartRate']\n",
    "legend_title = 'HR_Measures:'\n",
    "l_labels = ['High freq. Amp.', 'CoV 10s', 'HeartRate']\n",
    "\n",
    "\n",
    "row = 0\n",
    "for mouse in df_nan_check['Animal_ID'].unique():\n",
    "    for column in range(7):\n",
    "        session = ['OF', 'EPM', 'PreExp', 'CD1', 'CD2', 'Ext', 'ExtCont'][column]\n",
    "        if session == 'Ext':\n",
    "            if df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[0]].shape[0] == 0:\n",
    "                session = 'ExtHC'\n",
    "        fig.add_subplot(gs[row, column])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[0]], color='blue', alpha=0.75, label=l_labels[0])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[1]], color='darkorange', alpha=0.75, label=l_labels[1])\n",
    "        #plt.plot(df.loc[(df['Exclude'] == False) & (df['Animal_ID'] == mouse) & (df['Session'] == session), l_measures[2]], color='cyan', alpha=0.75, label=l_labels[2])\n",
    "        plt.plot(df_nan_check.loc[(df_nan_check['Exclude'] == False) & (df_nan_check['Animal_ID'] == mouse) & (df_nan_check['Session'] == session), l_measures[2]], color='k', alpha=0.5, label=l_labels[2])\n",
    "        plt.ylim(0,1)\n",
    "        if column == 0:\n",
    "            plt.ylabel(mouse)\n",
    "        if row == 0:\n",
    "            if session == 'Ext':\n",
    "                plt.title('Ext / ExtHC')\n",
    "            elif session == 'ExtHC':\n",
    "                plt.title('Ext / ExtHC')\n",
    "            else:\n",
    "                plt.title(session)\n",
    "            \n",
    "        if column == 6:\n",
    "            plt.legend(title= legend_title, loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "        else:\n",
    "            plt.legend('', frameon=False)\n",
    "    row = row + 1\n",
    "\n",
    "plt.savefig('HR_Amps_all_sessions_v10_NaNs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much of the data is classified as behavioral events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = df.loc[df['Exclude'] == False].shape[0]\n",
    "\n",
    "print('Percentage of datapoints for each behavioral category: \\n')\n",
    "for behavior in df['behaviors'].unique():\n",
    "    bin_count = df.loc[(df['Exclude'] == False) & (df['behaviors'] == behavior)].shape[0]\n",
    "    percentage = round(bin_count / all_data *100, 2)\n",
    "    \n",
    "    print(behavior + ': ' + str(percentage) + '% [' + str(bin_count) + ' bins]')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Side note:* still 'multiple' as behavioral score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['behaviors'] == 'multiple') & (df['Flight'] == 0), ['Animal_ID', 'Session', 'Bin', 'Remaining', 'Immobility', 'Rearing', 'StretchAttend', 'Grooming', 'Flight', 'TailRattling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
